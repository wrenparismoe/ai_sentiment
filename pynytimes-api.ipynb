{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import requests\n",
    "# import json\n",
    "# import os.path\n",
    "# import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pynytimes import NYTAPI\n",
    "NYT_API_KEY='e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = NYTAPI(NYT_API_KEY, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ai_concat_pivot.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 8\n",
    "\n",
    "# article = data.loc[ind, :]\n",
    "# article_title = \"dashdyuisgfkasdgf\" #article['Title']\n",
    "# url = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?q={article_title}&api-key={NYT_API_KEY}' # &fq=source:(\"The New York Times\")\n",
    "# query = requests.get(url)\n",
    "# query_data = query.json()['response']['docs'][0]\n",
    "\n",
    "# query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the indices of the missing dates\n",
    "# missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# # Extract the titles corresponding to the missing dates\n",
    "# missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "# # Function to fetch article dates using the New York Times API\n",
    "# def fetch_article_dates(titles):\n",
    "#     titles_len = len(titles)\n",
    "#     article_dates = []\n",
    "#     for i, title in enumerate(titles):\n",
    "#         try:\n",
    "#             url = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?q={title}&api-key={NYT_API_KEY}' # &fq=source:(\"The New York Times\")\n",
    "#             # article = nyt.article_search(query=title, results=1)\n",
    "#             query = requests.get(url)\n",
    "#             query_data = query.json()['response']['docs'][0]\n",
    "#             article_date = query_data['pub_date']\n",
    "#             # Convert to the desired format\n",
    "#             article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#             article_dates.append(article_date)\n",
    "#             print(f\"Progress: {i}/{titles_len}\")\n",
    "#         except Exception as e:\n",
    "#             print(\"Error: {}\".format(e))\n",
    "#             article_dates.append(np.nan)\n",
    "#     return article_dates\n",
    "\n",
    "# # Batch processing - fetch the article dates for the missing titles\n",
    "# article_dates = fetch_article_dates(missing_titles)\n",
    "\n",
    "# # Update the DataFrame with the fetched article dates\n",
    "# data.loc[missing_dates_indices, 'Article Date'] = article_dates\n",
    "\n",
    "# # Print progress\n",
    "# print(f\"Progress: {len(missing_titles)}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if progress file exists\n",
    "# progress_file = 'progress.csv'\n",
    "# if os.path.isfile(progress_file):\n",
    "#     # If progress file exists, read the progress from it\n",
    "#     progress = pd.read_csv(progress_file, index_col=0)\n",
    "#     start_index = progress.index[-1] + 1\n",
    "#     print(f\"Resuming from index {start_index}\")\n",
    "# else:\n",
    "#     # If progress file does not exist, start from the beginning\n",
    "#     start_index = 0\n",
    "#     progress = pd.DataFrame(columns=['Title', 'Article Date'])\n",
    "\n",
    "# # Find the indices of the missing dates\n",
    "# missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# # Extract the titles corresponding to the missing dates\n",
    "# missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "# # Function to fetch article dates using the New York Times API\n",
    "# def fetch_article_dates(titles):\n",
    "#     titles_len = len(titles)\n",
    "#     article_dates = []\n",
    "#     for i, title in enumerate(titles):\n",
    "#         try:\n",
    "#             article = nyt.article_search(query=title, results=1)\n",
    "#             if article:\n",
    "#                 article_date = article[0]['pub_date']\n",
    "#                 # Convert to the desired format\n",
    "#                 article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#                 article_dates.append(article_date)\n",
    "#             else:\n",
    "#                 print(f\"Error: No article found for {title}\")\n",
    "#                 article_dates.append(np.nan)\n",
    "#             print(f\"Progress: {i}/{titles_len}\")\n",
    "#         except Exception as e:\n",
    "#             print(\"Error: {}\".format(e))\n",
    "#             article_dates.append(np.nan)\n",
    "#         # Write progress to CSV file after every 10 titles\n",
    "#         if i % 10 == 0:\n",
    "#             progress.loc[start_index+i] = [title, article_dates[-1]]\n",
    "#             progress.to_csv(progress_file)\n",
    "#             time.sleep(1) # Wait for 1 second to avoid API rate limit\n",
    "\n",
    "#     return article_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing - fetch the article dates for the missing titles\n",
    "article_dates = fetch_article_dates(missing_titles[start_index:])\n",
    "\n",
    "# Update the DataFrame with the fetched article dates\n",
    "data.loc[missing_dates_indices, 'Article Date'] = article_dates\n",
    "\n",
    "# Print progress\n",
    "print(f\"Progress: {len(missing_titles)}/{len(data)}\")\n",
    "\n",
    "# Write progress to CSV file\n",
    "progress.loc[start_index:start_index+len(article_dates)-1] = [missing_titles[start_index:], article_dates]\n",
    "progress.to_csv(progress_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of the missing dates\n",
    "missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# Extract the titles corresponding to the missing dates\n",
    "missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "print(len(missing_titles))\n",
    "\n",
    "# Function to fetch article dates using the New York Times API\n",
    "def fetch_article_dates(titles):\n",
    "    titles_len = len(titles)\n",
    "    article_dates = []\n",
    "    for i, title in enumerate(titles):\n",
    "        try:\n",
    "            article = nyt.article_search(query=title, results=1)\n",
    "            if article:\n",
    "                article_date = article[0]['pub_date']\n",
    "                # Convert to the desired format\n",
    "                article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                article_dates.append(article_date)\n",
    "            else:\n",
    "                print(f\"Error: No article found for {title}\")\n",
    "                article_dates.append(np.nan)\n",
    "            print(f\"Progress: {i}/{titles_len}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "            article_dates.append(np.nan)\n",
    "    return article_dates\n",
    "\n",
    "# Batch processing - fetch the article dates for the missing titles\n",
    "# article_dates = fetch_article_dates(missing_titles)\n",
    "\n",
    "# Update the DataFrame with the fetched article dates\n",
    "# data.loc[missing_dates_indices, 'Article Date'] = article_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with parallel processing\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    article_dates = list(executor.map(fetch_article_dates, missing_titles))\n",
    "\n",
    "data.loc[missing_dates_indices, 'Article Date'] = article_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pynytimes library to fill article dates of missing values in 'Article Date' column of dataset\n",
    "for i in range(len(data)):\n",
    "    if pd.isnull(data['Article Date'][i]):\n",
    "        try:\n",
    "            article = nyt.article_search(\n",
    "                query = data['Title'][i],\n",
    "                results = 1,\n",
    "            )\n",
    "            # get missing article date\n",
    "            article_date = article[0]['pub_date']\n",
    "            # convert article_date datetime.datetime (e.g: 1993-09-22 05:00:00+00:00) to yyyy-mm-dd hh:mm:ss date format\n",
    "            article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "            # NOTE: This is inefficient\n",
    "            data.loc[i, 'Article Date'] = article_date\n",
    "            # print progress\n",
    "            print(f\"Progress: {i}/{len(data)}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "            # if there is an error, set article date to NaN\n",
    "            data.loc[i, 'Article Date'] = np.nan\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaNs in 'Article Date' column\n",
    "print(f\"Missing values in 'Article Date' column: {data['Article Date'].isnull().sum()} / {data.shape[0]} ({round(data['Article Date'].isnull().sum()/data.shape[0]*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
