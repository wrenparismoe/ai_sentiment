{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import requests\n",
    "# import json\n",
    "import os.path\n",
    "import time\n",
    "from pynytimes import NYTAPI\n",
    "NYT_API_KEY='e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = NYTAPI(NYT_API_KEY, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ai_concat_pivot.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 8\n",
    "\n",
    "# article = data.loc[ind, :]\n",
    "# article_title = \"dashdyuisgfkasdgf\" #article['Title']\n",
    "# url = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?q={article_title}&api-key={NYT_API_KEY}' # &fq=source:(\"The New York Times\")\n",
    "# query = requests.get(url)\n",
    "# query_data = query.json()['response']['docs'][0]\n",
    "\n",
    "# query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the indices of the missing dates\n",
    "# missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# # Extract the titles corresponding to the missing dates\n",
    "# missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "# # Function to fetch article dates using the New York Times API\n",
    "# def fetch_article_dates(titles):\n",
    "#     titles_len = len(titles)\n",
    "#     article_dates = []\n",
    "#     for i, title in enumerate(titles):\n",
    "#         try:\n",
    "#             url = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?q={title}&api-key={NYT_API_KEY}' # &fq=source:(\"The New York Times\")\n",
    "#             # article = nyt.article_search(query=title, results=1)\n",
    "#             query = requests.get(url)\n",
    "#             query_data = query.json()['response']['docs'][0]\n",
    "#             article_date = query_data['pub_date']\n",
    "#             # Convert to the desired format\n",
    "#             article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#             article_dates.append(article_date)\n",
    "#             print(f\"Progress: {i}/{titles_len}\")\n",
    "#         except Exception as e:\n",
    "#             print(\"Error: {}\".format(e))\n",
    "#             article_dates.append(np.nan)\n",
    "#     return article_dates\n",
    "\n",
    "# # Batch processing - fetch the article dates for the missing titles\n",
    "# article_dates = fetch_article_dates(missing_titles)\n",
    "\n",
    "# # Update the DataFrame with the fetched article dates\n",
    "# data.loc[missing_dates_indices, 'Article Date'] = article_dates\n",
    "\n",
    "# # Print progress\n",
    "# print(f\"Progress: {len(missing_titles)}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index 31\n"
     ]
    }
   ],
   "source": [
    "# Check if progress file exists\n",
    "progress_file = 'progress.csv'\n",
    "if os.path.isfile(progress_file):\n",
    "    # If progress file exists, read the progress from it\n",
    "    progress = pd.read_csv(progress_file, index_col=0)\n",
    "    start_index = progress.index[-1] + 1\n",
    "    print(f\"Resuming from index {start_index}\")\n",
    "else:\n",
    "    # If progress file does not exist, start from the beginning\n",
    "    start_index = 0\n",
    "    progress = pd.DataFrame(columns=['Title', 'Article Date'])\n",
    "\n",
    "# Find the indices of the missing dates\n",
    "missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# Extract the titles corresponding to the missing dates\n",
    "missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "# Function to fetch article dates using the New York Times API\n",
    "def fetch_article_dates(titles):\n",
    "    titles_len = len(titles)\n",
    "    article_dates = []\n",
    "    for i, title in enumerate(titles):\n",
    "        try:\n",
    "            article = nyt.article_search(query=title, results=1)\n",
    "            if article:\n",
    "                article_date = article[0]['pub_date']\n",
    "                # Convert to the desired format\n",
    "                article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                article_dates.append(article_date)\n",
    "            else:\n",
    "                print(f\"Error: No article found for {title}\")\n",
    "                article_dates.append(np.nan)\n",
    "            print(f\"Progress: {i}/{titles_len}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "            article_dates.append(np.nan)\n",
    "        # Write progress to CSV file after every 10 titles\n",
    "        if i % 10 == 0:\n",
    "            progress.loc[start_index+i] = [title, article_dates[-1]]\n",
    "            progress.to_csv(progress_file)\n",
    "            time.sleep(1) # Wait for 1 second to avoid API rate limit\n",
    "\n",
    "    return article_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing - fetch the article dates for the missing titles\n",
    "article_dates = fetch_article_dates(missing_titles[start_index:])\n",
    "\n",
    "# Update the DataFrame with the fetched article dates\n",
    "data.loc[missing_dates_indices, 'Article Date'] = article_dates\n",
    "\n",
    "# Print progress\n",
    "print(f\"Progress: {len(missing_titles)}/{len(data)}\")\n",
    "\n",
    "# Write progress to CSV file\n",
    "progress.loc[start_index:start_index+len(article_dates)-1] = [missing_titles[start_index:], article_dates]\n",
    "progress.to_csv(progress_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/1489\n",
      "Progress: 1/1489\n",
      "Progress: 2/1489\n",
      "Progress: 3/1489\n",
      "Progress: 4/1489\n",
      "Progress: 5/1489\n",
      "Progress: 6/1489\n",
      "Progress: 7/1489\n",
      "Progress: 8/1489\n",
      "Progress: 9/1489\n",
      "Progress: 10/1489\n",
      "Progress: 11/1489\n",
      "Progress: 12/1489\n",
      "Progress: 13/1489\n",
      "Progress: 14/1489\n",
      "Progress: 15/1489\n",
      "Progress: 16/1489\n",
      "Progress: 17/1489\n",
      "Progress: 18/1489\n",
      "Progress: 19/1489\n",
      "Progress: 20/1489\n",
      "Progress: 21/1489\n",
      "Progress: 22/1489\n",
      "Progress: 23/1489\n",
      "Progress: 24/1489\n",
      "Progress: 25/1489\n",
      "Progress: 26/1489\n",
      "Progress: 27/1489\n",
      "Progress: 28/1489\n",
      "Progress: 29/1489\n",
      "Progress: 30/1489\n",
      "Progress: 31/1489\n",
      "Progress: 32/1489\n",
      "Progress: 33/1489\n",
      "Progress: 34/1489\n",
      "Progress: 35/1489\n",
      "Progress: 36/1489\n",
      "Progress: 37/1489\n",
      "Progress: 38/1489\n",
      "Progress: 39/1489\n",
      "Progress: 40/1489\n",
      "Progress: 41/1489\n",
      "Progress: 42/1489\n",
      "Progress: 43/1489\n",
      "Progress: 44/1489\n",
      "Progress: 45/1489\n",
      "Progress: 46/1489\n",
      "Progress: 47/1489\n",
      "Progress: 48/1489\n",
      "Progress: 49/1489\n",
      "Progress: 50/1489\n",
      "Progress: 51/1489\n",
      "Progress: 52/1489\n",
      "Progress: 53/1489\n",
      "Progress: 54/1489\n",
      "Progress: 55/1489\n",
      "Progress: 56/1489\n",
      "Error: No article found for SNAGS IMPERIL JAPAN'S DREAM OF WORLD'S FASTEST COMPUTER\n",
      "Progress: 57/1489\n",
      "Progress: 58/1489\n",
      "Progress: 59/1489\n",
      "Progress: 60/1489\n",
      "Progress: 61/1489\n",
      "Progress: 62/1489\n",
      "Progress: 63/1489\n",
      "Progress: 64/1489\n",
      "Progress: 65/1489\n",
      "Progress: 66/1489\n",
      "Progress: 67/1489\n",
      "Progress: 68/1489\n",
      "Progress: 69/1489\n",
      "Progress: 70/1489\n",
      "Progress: 71/1489\n",
      "Progress: 72/1489\n",
      "Progress: 73/1489\n",
      "Progress: 74/1489\n",
      "Progress: 75/1489\n",
      "Progress: 76/1489\n",
      "Progress: 77/1489\n",
      "Progress: 78/1489\n",
      "Progress: 79/1489\n",
      "Progress: 80/1489\n",
      "Progress: 81/1489\n",
      "Progress: 82/1489\n",
      "Progress: 83/1489\n",
      "Progress: 84/1489\n",
      "Progress: 85/1489\n",
      "Progress: 86/1489\n",
      "Progress: 87/1489\n",
      "Progress: 88/1489\n",
      "Progress: 89/1489\n",
      "Progress: 90/1489\n",
      "Progress: 91/1489\n",
      "Progress: 92/1489\n",
      "Progress: 93/1489\n",
      "Progress: 94/1489\n",
      "Progress: 95/1489\n",
      "Progress: 96/1489\n",
      "Progress: 97/1489\n",
      "Progress: 98/1489\n",
      "Progress: 99/1489\n",
      "Progress: 100/1489\n",
      "Progress: 101/1489\n",
      "Progress: 102/1489\n",
      "Progress: 103/1489\n",
      "Progress: 104/1489\n",
      "Progress: 105/1489\n",
      "Progress: 106/1489\n",
      "Progress: 107/1489\n",
      "Progress: 108/1489\n",
      "Progress: 109/1489\n",
      "Progress: 110/1489\n",
      "Progress: 111/1489\n",
      "Progress: 112/1489\n",
      "Progress: 113/1489\n",
      "Progress: 114/1489\n",
      "Progress: 115/1489\n",
      "Progress: 116/1489\n",
      "Progress: 117/1489\n",
      "Progress: 118/1489\n",
      "Progress: 119/1489\n",
      "Progress: 120/1489\n",
      "Progress: 121/1489\n",
      "Progress: 122/1489\n",
      "Progress: 123/1489\n",
      "Progress: 124/1489\n",
      "Progress: 125/1489\n",
      "Progress: 126/1489\n",
      "Progress: 127/1489\n",
      "Progress: 128/1489\n",
      "Progress: 129/1489\n",
      "Progress: 130/1489\n",
      "Progress: 131/1489\n",
      "Progress: 132/1489\n",
      "Progress: 133/1489\n",
      "Progress: 134/1489\n",
      "Progress: 135/1489\n",
      "Progress: 136/1489\n",
      "Progress: 137/1489\n",
      "Progress: 138/1489\n",
      "Progress: 139/1489\n",
      "Progress: 140/1489\n",
      "Progress: 141/1489\n",
      "Progress: 142/1489\n",
      "Progress: 143/1489\n",
      "Progress: 144/1489\n",
      "Progress: 145/1489\n",
      "Progress: 146/1489\n",
      "Progress: 147/1489\n",
      "Progress: 148/1489\n",
      "Progress: 149/1489\n",
      "Progress: 150/1489\n",
      "Progress: 151/1489\n",
      "Progress: 152/1489\n",
      "Progress: 153/1489\n",
      "Progress: 154/1489\n",
      "Progress: 155/1489\n",
      "Progress: 156/1489\n",
      "Progress: 157/1489\n",
      "Progress: 158/1489\n",
      "Progress: 159/1489\n",
      "Progress: 160/1489\n",
      "Progress: 161/1489\n",
      "Progress: 162/1489\n",
      "Progress: 163/1489\n",
      "Progress: 164/1489\n",
      "Progress: 165/1489\n",
      "Progress: 166/1489\n",
      "Progress: 167/1489\n",
      "Progress: 168/1489\n",
      "Progress: 169/1489\n",
      "Progress: 170/1489\n",
      "Progress: 171/1489\n",
      "Progress: 172/1489\n",
      "Progress: 173/1489\n",
      "Progress: 174/1489\n",
      "Progress: 175/1489\n",
      "Progress: 176/1489\n",
      "Progress: 177/1489\n",
      "Progress: 178/1489\n",
      "Progress: 179/1489\n",
      "Progress: 180/1489\n",
      "Error: No article found for Best Sellers: Hardcover Fiction: Sunday, June 26th 2011\n",
      "Progress: 181/1489\n",
      "Progress: 182/1489\n",
      "Progress: 183/1489\n",
      "Progress: 184/1489\n",
      "Error: No article found for Paid Notice: Deaths  SAUVAGEOT, HENRY E\n",
      "Progress: 185/1489\n",
      "Progress: 186/1489\n",
      "Progress: 187/1489\n",
      "Progress: 188/1489\n",
      "Progress: 189/1489\n",
      "Progress: 190/1489\n",
      "Progress: 191/1489\n",
      "Progress: 192/1489\n",
      "Progress: 193/1489\n",
      "Progress: 194/1489\n",
      "Progress: 195/1489\n",
      "Progress: 196/1489\n",
      "Progress: 197/1489\n",
      "Error: No article found for Richard Wright's Estate Calls Google Book Settlement 'Grievously Flawed'\n",
      "Progress: 198/1489\n",
      "Progress: 199/1489\n",
      "Progress: 200/1489\n",
      "Progress: 201/1489\n",
      "Progress: 202/1489\n",
      "Progress: 203/1489\n",
      "Progress: 204/1489\n",
      "Progress: 205/1489\n",
      "Progress: 206/1489\n",
      "Progress: 207/1489\n",
      "Progress: 208/1489\n",
      "Progress: 209/1489\n",
      "Progress: 210/1489\n",
      "Progress: 211/1489\n",
      "Progress: 212/1489\n",
      "Progress: 213/1489\n",
      "Progress: 214/1489\n",
      "Progress: 215/1489\n",
      "Progress: 216/1489\n",
      "Progress: 217/1489\n",
      "Progress: 218/1489\n",
      "Progress: 219/1489\n",
      "Progress: 220/1489\n",
      "Progress: 221/1489\n",
      "Progress: 222/1489\n",
      "Progress: 223/1489\n",
      "Progress: 224/1489\n",
      "Progress: 225/1489\n",
      "Progress: 226/1489\n",
      "Progress: 227/1489\n",
      "Progress: 228/1489\n",
      "Progress: 229/1489\n",
      "Progress: 230/1489\n",
      "Progress: 231/1489\n",
      "Progress: 232/1489\n",
      "Progress: 233/1489\n",
      "Progress: 234/1489\n",
      "Progress: 235/1489\n",
      "Progress: 236/1489\n",
      "Progress: 237/1489\n",
      "Progress: 238/1489\n",
      "Progress: 239/1489\n",
      "Progress: 240/1489\n",
      "Progress: 241/1489\n",
      "Progress: 242/1489\n",
      "Progress: 243/1489\n",
      "Progress: 244/1489\n",
      "Progress: 245/1489\n",
      "Progress: 246/1489\n",
      "Progress: 247/1489\n",
      "Progress: 248/1489\n",
      "Progress: 249/1489\n",
      "Progress: 250/1489\n",
      "Progress: 251/1489\n",
      "Progress: 252/1489\n",
      "Progress: 253/1489\n",
      "Progress: 254/1489\n",
      "Progress: 255/1489\n",
      "Progress: 256/1489\n",
      "Progress: 257/1489\n",
      "Progress: 258/1489\n",
      "Progress: 259/1489\n",
      "Progress: 260/1489\n",
      "Progress: 261/1489\n",
      "Progress: 262/1489\n",
      "Progress: 263/1489\n",
      "Progress: 264/1489\n",
      "Progress: 265/1489\n",
      "Progress: 266/1489\n",
      "Progress: 267/1489\n",
      "Progress: 268/1489\n",
      "Progress: 269/1489\n",
      "Progress: 270/1489\n",
      "Progress: 271/1489\n",
      "Progress: 272/1489\n",
      "Progress: 273/1489\n",
      "Progress: 274/1489\n",
      "Progress: 275/1489\n",
      "Progress: 276/1489\n",
      "Progress: 277/1489\n",
      "Progress: 278/1489\n",
      "Progress: 279/1489\n",
      "Progress: 280/1489\n",
      "Progress: 281/1489\n",
      "Progress: 282/1489\n",
      "Progress: 283/1489\n",
      "Progress: 284/1489\n",
      "Progress: 285/1489\n",
      "Progress: 286/1489\n",
      "Progress: 287/1489\n",
      "Progress: 288/1489\n",
      "Progress: 289/1489\n",
      "Progress: 290/1489\n",
      "Progress: 291/1489\n",
      "Progress: 292/1489\n",
      "Progress: 293/1489\n",
      "Progress: 294/1489\n",
      "Progress: 295/1489\n",
      "Progress: 296/1489\n",
      "Progress: 297/1489\n",
      "Progress: 298/1489\n",
      "Progress: 299/1489\n",
      "Progress: 300/1489\n",
      "Progress: 301/1489\n",
      "Progress: 302/1489\n",
      "Progress: 303/1489\n",
      "Progress: 304/1489\n",
      "Progress: 305/1489\n",
      "Progress: 306/1489\n",
      "Progress: 307/1489\n",
      "Progress: 308/1489\n",
      "Progress: 309/1489\n",
      "Progress: 310/1489\n",
      "Progress: 311/1489\n",
      "Progress: 312/1489\n",
      "Progress: 313/1489\n",
      "Progress: 314/1489\n",
      "Progress: 315/1489\n",
      "Progress: 316/1489\n",
      "Progress: 317/1489\n",
      "Progress: 318/1489\n",
      "Progress: 319/1489\n",
      "Progress: 320/1489\n",
      "Progress: 321/1489\n",
      "Progress: 322/1489\n",
      "Progress: 323/1489\n",
      "Progress: 324/1489\n",
      "Progress: 325/1489\n",
      "Error: HTTPSConnectionPool(host='api.nytimes.com', port=443): Max retries exceeded with url: /svc/search/v2/articlesearch.json?api-key=e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8&fq=&q=John+Henry+Holland%2C+Who+Computerized+Evolution%2C+Dies+at+86&page=0 (Caused by ResponseError('too many 429 error responses'))\n",
      "Error: HTTPSConnectionPool(host='api.nytimes.com', port=443): Max retries exceeded with url: /svc/search/v2/articlesearch.json?api-key=e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8&fq=&q=%E2%80%98Machines+of+Loving+Grace%2C%E2%80%99+by+John+Markoff&page=0 (Caused by ResponseError('too many 429 error responses'))\n",
      "Error: HTTPSConnectionPool(host='api.nytimes.com', port=443): Max retries exceeded with url: /svc/search/v2/articlesearch.json?api-key=e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8&fq=&q=IPhone+6s%E2%80%99s+Hands-Free+Siri+Is+an+Omen+of+the+Future&page=0 (Caused by ResponseError('too many 429 error responses'))\n",
      "Error: HTTPSConnectionPool(host='api.nytimes.com', port=443): Max retries exceeded with url: /svc/search/v2/articlesearch.json?api-key=e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8&fq=&q=Start-Ups+Picked+by+Disney+Hint+at+Future+Tech+for+Children&page=0 (Caused by ResponseError('too many 429 error responses'))\n",
      "Error: HTTPSConnectionPool(host='api.nytimes.com', port=443): Max retries exceeded with url: /svc/search/v2/articlesearch.json?api-key=e1RpBU3JBdcJ0dWyz6mB61EiXWG1DsM8&fq=&q=Computer+Scientists+Wield+Artificial+Intelligence+to+Battle+Tax+Evasion&page=0 (Caused by ResponseError('too many 429 error responses'))\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of the missing dates\n",
    "missing_dates_indices = data['Article Date'].isnull()\n",
    "\n",
    "# Extract the titles corresponding to the missing dates\n",
    "missing_titles = data.loc[missing_dates_indices, 'Title']\n",
    "\n",
    "# Function to fetch article dates using the New York Times API\n",
    "def fetch_article_dates(titles):\n",
    "    titles_len = len(titles)\n",
    "    article_dates = []\n",
    "    for i, title in enumerate(titles):\n",
    "        try:\n",
    "            article = nyt.article_search(query=title, results=1)\n",
    "            if article:\n",
    "                article_date = article[0]['pub_date']\n",
    "                # Convert to the desired format\n",
    "                article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                article_dates.append(article_date)\n",
    "            else:\n",
    "                print(f\"Error: No article found for {title}\")\n",
    "                article_dates.append(np.nan)\n",
    "            print(f\"Progress: {i}/{titles_len}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "            article_dates.append(np.nan)\n",
    "    return article_dates\n",
    "\n",
    "# Batch processing - fetch the article dates for the missing titles\n",
    "article_dates = fetch_article_dates(missing_titles)\n",
    "\n",
    "# Update the DataFrame with the fetched article dates\n",
    "data.loc[missing_dates_indices, 'Article Date'] = article_dates\n",
    "\n",
    "# Print progress\n",
    "print(f\"Progress: {len(missing_titles)}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use pynytimes library to fill article dates of missing values in 'Article Date' column of dataset\n",
    "# for i in range(len(data)):\n",
    "#     if pd.isnull(data['Article Date'][i]):\n",
    "#         try:\n",
    "#             article = nyt.article_search(\n",
    "#                 query = data['Title'][i],\n",
    "#                 results = 1,\n",
    "#             )\n",
    "#             # get missing article date\n",
    "#             article_date = article[0]['pub_date']\n",
    "#             # convert article_date datetime.datetime (e.g: 1993-09-22 05:00:00+00:00) to yyyy-mm-dd hh:mm:ss date format\n",
    "#             article_date = article_date.strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "#             # NOTE: This is inefficient\n",
    "#             data.loc[i, 'Article Date'] = article_date\n",
    "#             # print progress\n",
    "#             print(f\"Progress: {i}/{len(data)}\")\n",
    "#         except Exception as e:\n",
    "#             print(\"Error: {}\".format(e))\n",
    "#             # if there is an error, set article date to NaN\n",
    "#             data.loc[i, 'Article Date'] = np.nan\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaNs in 'Article Date' column\n",
    "print(f\"Missing values in 'Article Date' column: {data['Article Date'].isnull().sum()} / {data.shape[0]} ({round(data['Article Date'].isnull().sum()/data.shape[0]*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
