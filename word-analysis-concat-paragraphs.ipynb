{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import string\n",
    "# Importing nltk resources for text preprocessing\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "import re\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Cyborg (positive)</th>\n",
       "      <th>Decisions (positive)</th>\n",
       "      <th>Education (positive)</th>\n",
       "      <th>Entertain (positive)</th>\n",
       "      <th>...</th>\n",
       "      <th>Cyborg (negative)</th>\n",
       "      <th>Ethics (negative)</th>\n",
       "      <th>Military (negative)</th>\n",
       "      <th>Progress (negative)</th>\n",
       "      <th>Singularity (negative)</th>\n",
       "      <th>Work (negative)</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd100e58eb7c8105d5bbb33</td>\n",
       "      <td>2012-04-01 00:00:00 UTC</td>\n",
       "      <td>Arts; Style; Magazine</td>\n",
       "      <td>9. The robot designs woven into these tea towe...</td>\n",
       "      <td>Stijl Council</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science; Health</td>\n",
       "      <td>In 1818, Mary Shelley's ''Frankenstein'' raise...</td>\n",
       "      <td>Statues to Golems to R2-D2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd14a668eb7c8105d627c40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business; Opinion</td>\n",
       "      <td>Mr. Culbertson would use ''powerful new tools'...</td>\n",
       "      <td>ECONOMIC POLICY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td></td>\n",
       "      <td>manage entire economies AI and computers could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd14a678eb7c8105d627d24</td>\n",
       "      <td>1986-02-16 00:00:00 UTC</td>\n",
       "      <td>Business</td>\n",
       "      <td>Some golfer. Fortunately, you'll never have to...</td>\n",
       "      <td>IN PURSUIT OF THE PERFECT GOLF BALL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>1986-02-16 00:00:00 UTC</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>All week long Navy divers and salvage experts ...</td>\n",
       "      <td>LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID             Article Date            NYT section  \\\n",
       "0  4fd100e58eb7c8105d5bbb33  2012-04-01 00:00:00 UTC  Arts; Style; Magazine   \n",
       "1  4fd100e88eb7c8105d5bbd2d                      NaN        Science; Health   \n",
       "2  4fd14a668eb7c8105d627c40                      NaN      Business; Opinion   \n",
       "3  4fd14a678eb7c8105d627d24  1986-02-16 00:00:00 UTC               Business   \n",
       "4  4fd14a678eb7c8105d627d35  1986-02-16 00:00:00 UTC                   U.S.   \n",
       "\n",
       "                                           Paragraph  \\\n",
       "0  9. The robot designs woven into these tea towe...   \n",
       "1  In 1818, Mary Shelley's ''Frankenstein'' raise...   \n",
       "2  Mr. Culbertson would use ''powerful new tools'...   \n",
       "3  Some golfer. Fortunately, you'll never have to...   \n",
       "4  All week long Navy divers and salvage experts ...   \n",
       "\n",
       "                                               Title  Fiction  \\\n",
       "0                                      Stijl Council        0   \n",
       "1                         Statues to Golems to R2-D2        2   \n",
       "2                                    ECONOMIC POLICY        0   \n",
       "3                IN PURSUIT OF THE PERFECT GOLF BALL        0   \n",
       "4  LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...        0   \n",
       "\n",
       "   Cyborg (positive)  Decisions (positive)  Education (positive)  \\\n",
       "0                  0                     0                     0   \n",
       "1                  0                     0                     0   \n",
       "2                  0                     2                     0   \n",
       "3                  0                     0                     0   \n",
       "4                  0                     0                     0   \n",
       "\n",
       "   Entertain (positive)  ...  Cyborg (negative)  Ethics (negative)  \\\n",
       "0                     0  ...                  0                  0   \n",
       "1                     0  ...                  0                  1   \n",
       "2                     0  ...                  0                  0   \n",
       "3                     0  ...                  0                  0   \n",
       "4                     0  ...                  0                  0   \n",
       "\n",
       "   Military (negative)  Progress (negative)  Singularity (negative)  \\\n",
       "0                    0                    0                       0   \n",
       "1                    2                    0                       1   \n",
       "2                    0                    0                       0   \n",
       "3                    0                    0                       0   \n",
       "4                    0                    0                       0   \n",
       "\n",
       "   Work (negative)   AI Mood  AI Relevance  Other (negative)  \\\n",
       "0                0  3.000000      2.333333                     \n",
       "1                0  2.333333      5.000000                     \n",
       "2                0  4.000000      4.333333                     \n",
       "3                0  3.000000      4.000000                     \n",
       "4                0  3.000000      3.333333                     \n",
       "\n",
       "                                    Other (positive)  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  manage entire economies AI and computers could...  \n",
       "3                                                     \n",
       "4                                                     \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data/ai-perception-concat-paragraphs.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# display first 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3365\n",
      "Number of NaNs in 'Article Date' column:  1418 (42.14%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows:\", data.shape[0])\n",
    "# Count NaNs in 'Article Date' column\n",
    "print(\"Number of NaNs in 'Article Date' column: \", data['Article Date'].isnull().sum(), f\"({round(data['Article Date'].isnull().sum()/data.shape[0]*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'Article Date' in datetime64[ns, UTC] format and change to 'Article Year' in int64 format\n",
    "# Convert the 'Article Date' column to datetime, coercing errors\n",
    "# data['Article Date'] = pd.to_datetime(data['Article Date'], errors='coerce')\n",
    "# data['Article Year'] = data['Article Date'].dt.year\n",
    "# # convert to int64 - ignore nulls\n",
    "# data['Article Year'] = data['Article Year'].fillna(0)\n",
    "# data['Article Year'] = data['Article Year'].astype('int64')\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common English stop words - set class data type\n",
    "stop_words = {'thus', 'the', 'and', 'to', 'of', 'a', 'in', 'that', 'is', 'was', 'he', 'for', 'it', 'with', 'as', 'his', 'on', 'be', 'at', 'by', 'i', 'this', 'had', 'not', 'but', 'from', 'or', 'have', 'an', 'they', 'which', 'you', 'were', 'her', 'their', 'we', 'its', 'said', 'like', '—', '——', '-', '--', '  '}\n",
    "\n",
    "# load frequent words dataset - columns are 'word' and 'count'\n",
    "freq_words = pd.read_csv('data/unigram_freq.csv')\n",
    "\n",
    "# add 1 and 2 letter words to the stop_words set if they are not already there\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if len(word) <= 2:\n",
    "        stop_words.add(word)\n",
    "\n",
    "# add stop words with count more than 550,000,000\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if freq_words['count'][i] > 550000000:\n",
    "        stop_words.add(word)\n",
    "\n",
    "# create pandas series with words with count less than 100,000\n",
    "less_freq_words = freq_words[freq_words['count'] < 100000]['word'].tail(100000).tolist()\n",
    "# add less_freq_words to stop_words set\n",
    "stop_words = stop_words.union(set(less_freq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233846, 2)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freq_words[freq_words['count'] > 550000000].shape\n",
    "freq_words[freq_words['count'] < 100000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100775\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "# Function to tokenize text (split by spaces and remove punctuation)\n",
    "def custom_tokenize(text):\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # write 'artificial intelligence' phrase as single hyphenated word 'artificial_intelligence'\n",
    "    text = text.replace(\"artificial intelligence\", \"artificial_intelligence\")\n",
    "    text = text.replace(\" ai \", \" AI \")\n",
    "    # Remove numbers and special characters but keep hyphenated words\n",
    "    text = re.sub(r'[^a-zA-Z0-9-]', ' ', text)\n",
    "    # Remove numbers\n",
    "    # text = re.sub(r'[0-9]', ' ', text)\n",
    "    # Tokenize by spaces\n",
    "    tokens = text.split()\n",
    "    # Include only correctly spelled words\n",
    "    tokens = [word for word in tokens if word in spell]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Updated function to preprocess text (tokenize and remove stop words) with handling for missing or non-string values\n",
    "def custom_preprocess_text(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = custom_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9. The robot designs woven into these tea towe...</td>\n",
       "      <td>[robot, designs, woven, into, these, tea, towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 1818, Mary Shelley's ''Frankenstein'' raise...</td>\n",
       "      <td>[mary, frankenstein, raised, specter, machines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Culbertson would use ''powerful new tools'...</td>\n",
       "      <td>[powerful, tools, model, manage, entire, econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some golfer. Fortunately, you'll never have to...</td>\n",
       "      <td>[some, golfer, fortunately, youll, never, meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All week long Navy divers and salvage experts ...</td>\n",
       "      <td>[week, long, navy, divers, salvage, experts, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Paragraph  \\\n",
       "0  9. The robot designs woven into these tea towe...   \n",
       "1  In 1818, Mary Shelley's ''Frankenstein'' raise...   \n",
       "2  Mr. Culbertson would use ''powerful new tools'...   \n",
       "3  Some golfer. Fortunately, you'll never have to...   \n",
       "4  All week long Navy divers and salvage experts ...   \n",
       "\n",
       "                                 Processed_Paragraph  \n",
       "0  [robot, designs, woven, into, these, tea, towe...  \n",
       "1  [mary, frankenstein, raised, specter, machines...  \n",
       "2  [powerful, tools, model, manage, entire, econo...  \n",
       "3  [some, golfer, fortunately, youll, never, meet...  \n",
       "4  [week, long, navy, divers, salvage, experts, u...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the custom preprocessing function to the 'Paragraph' column\n",
    "data['Processed_Paragraph'] = data['Paragraph'].apply(custom_preprocess_text)\n",
    "\n",
    "# Preview the processed paragraphs of the first few rows\n",
    "data[['Paragraph', 'Processed_Paragraph']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Word Associations (Positive and Negative)\n",
    "\n",
    "To find words with the most positive and negative associations, we analyze the processed paragraphs in conjunction with the positive and negative columns in the dataset. We create functions to aggregate the word counts based on these associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns representing positive and negative associations\n",
    "positive_columns = ['Cyborg (positive)', 'Decisions (positive)', 'Education (positive)', 'Entertain (positive)', 'Healthcare (positive)', 'Singularity (positive)', 'Transportation (positive)', 'Work (positive)']\n",
    "negative_columns = ['Controling AI (negative)', 'Cyborg (negative)', 'Ethics (negative)', 'Military (negative)', 'Progress (negative)', 'Singularity (negative)', 'Work (negative)']\n",
    "# Define remaining columns\n",
    "all_columns = data.columns.tolist()\n",
    "remaining_columns = [col for col in all_columns if col not in positive_columns and col not in negative_columns]\n",
    "\n",
    "# Function to count words with positive and negative associations\n",
    "def count_associations(row):\n",
    "    # Extract processed paragraph\n",
    "    words = row['Processed_Paragraph']\n",
    "    # Initialize counters for positive and negative associations\n",
    "    positive_counter = Counter()\n",
    "    negative_counter = Counter()\n",
    "    # Iterate through words and update counters based on associations in the row\n",
    "    for word in words:\n",
    "        if any(row[col] > 0 for col in positive_columns):\n",
    "            positive_counter[word] += 1\n",
    "        if any(row[col] > 0 for col in negative_columns):\n",
    "            negative_counter[word] += 1\n",
    "    return positive_counter, negative_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to count word associations\n",
    "positive_word_counts = Counter()\n",
    "negative_word_counts = Counter()\n",
    "# Create word count dataframe with 'Article ID', 'Article Date', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', '\n",
    "for _, row in data.iterrows():\n",
    "    positive, negative = count_associations(row)\n",
    "    positive_word_counts += positive\n",
    "    negative_word_counts += negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive word count: 14170\n",
      "negative word count: 10235\n"
     ]
    }
   ],
   "source": [
    "# print length of positive_word_counts and negative_word_counts dictionaries\n",
    "print('positive word count:', len(positive_word_counts))\n",
    "print('negative word count:', len(negative_word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot in positive words: True \n",
      "robot in negative words: True\n",
      "robot (positive): 2149\n",
      "robot (negative): 785\n"
     ]
    }
   ],
   "source": [
    "# check if 'robot' is contained in negative_word_counts\n",
    "print('robot in positive words:', 'robot' in positive_word_counts, '\\nrobot in negative words:', 'robot' in negative_word_counts)\n",
    "\n",
    "print('robot (positive):', positive_word_counts['robot'])\n",
    "print('robot (negative):', negative_word_counts['robot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check top positively and negatively associated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive: [('robot', 2149), ('intelligence', 1954), ('artificial', 1871), ('computer', 647), ('human', 597), ('technology', 562), ('robots', 522), ('AI', 490), ('could', 484), ('than', 460)] \n",
      "top negative: [('intelligence', 1278), ('artificial', 1187), ('robot', 785), ('human', 426), ('computer', 388), ('AI', 365), ('technology', 351), ('robots', 300), ('people', 271), ('could', 261)]\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 positive and negative words\n",
    "top_positive_words = positive_word_counts.most_common(10)\n",
    "top_negative_words = negative_word_counts.most_common(10)\n",
    "\n",
    "# top_positive_words, top_negative_words\n",
    "print('top positive:', top_positive_words, '\\ntop negative:', top_negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Sentiment Columns into Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>1986-08-10 00:00:00 UTC</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The robot must be keyed to a single individual...</td>\n",
       "      <td>TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>could be the tool that a handicapped person ...</td>\n",
       "      <td>[robot, must, keyed, single, individuals, voic...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4fd16d848eb7c8105d660007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The F.B.I. is enthusiastic about Big Floyd, wh...</td>\n",
       "      <td>'BIG FLOYD' JOINS THE FORCE</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>Criminal Investigation Lesser Crimes     diffe...</td>\n",
       "      <td>[fbi, enthusiastic, big, floyd, whose, namesak...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4fd1707b8eb7c8105d66317b</td>\n",
       "      <td>1986-08-10 00:00:00 UTC</td>\n",
       "      <td>Arts</td>\n",
       "      <td>''Condor,'' on the other hand, tries to be amu...</td>\n",
       "      <td>WHEN THE SLUSH PILE COMES TO LIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[condor, hand, tries, amusing, after, hero, se...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4fd1781e8eb7c8105d66ef93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>''The Tomorrow Makers,'' by Grant Fjermedal ($...</td>\n",
       "      <td>HOW TO AVOID TUNNEL VISION</td>\n",
       "      <td>0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>AI minds are wildly different from hum...</td>\n",
       "      <td>robotic immortality</td>\n",
       "      <td>[tomorrow, makers, grant, macmillan, volume, d...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4fd190318eb7c8105d696da7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology; Science; Week in Review</td>\n",
       "      <td>WHEN the computer scientist John McCarthy coin...</td>\n",
       "      <td>IDEAS AND TRENDS: Can Machines Learn to Think?...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>AI companies failing</td>\n",
       "      <td>science and technology development suppo...</td>\n",
       "      <td>[computer, scientist, john, mccarthy, coined, ...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Article ID             Article Date  \\\n",
       "16   4fd156a18eb7c8105d63aed2  1986-08-10 00:00:00 UTC   \n",
       "115  4fd16d848eb7c8105d660007                      NaN   \n",
       "125  4fd1707b8eb7c8105d66317b  1986-08-10 00:00:00 UTC   \n",
       "162  4fd1781e8eb7c8105d66ef93                      NaN   \n",
       "275  4fd190318eb7c8105d696da7                      NaN   \n",
       "\n",
       "                             NYT section  \\\n",
       "16                                  U.S.   \n",
       "115                                 U.S.   \n",
       "125                                 Arts   \n",
       "162                             Business   \n",
       "275  Technology; Science; Week in Review   \n",
       "\n",
       "                                             Paragraph  \\\n",
       "16   The robot must be keyed to a single individual...   \n",
       "115  The F.B.I. is enthusiastic about Big Floyd, wh...   \n",
       "125  ''Condor,'' on the other hand, tries to be amu...   \n",
       "162  ''The Tomorrow Makers,'' by Grant Fjermedal ($...   \n",
       "275  WHEN the computer scientist John McCarthy coin...   \n",
       "\n",
       "                                                 Title  Fiction   AI Mood  \\\n",
       "16        TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR        0  4.333333   \n",
       "115                        'BIG FLOYD' JOINS THE FORCE        0  3.666667   \n",
       "125                  WHEN THE SLUSH PILE COMES TO LIFE        1  3.000000   \n",
       "162                         HOW TO AVOID TUNNEL VISION        0  3.111111   \n",
       "275  IDEAS AND TRENDS: Can Machines Learn to Think?...        0  2.888889   \n",
       "\n",
       "     AI Relevance                                   Other (negative)  \\\n",
       "16       5.000000                                                      \n",
       "115      5.000000                                                      \n",
       "125      3.333333                                                      \n",
       "162      4.666667          AI minds are wildly different from hum...   \n",
       "275      4.555556                           AI companies failing       \n",
       "\n",
       "                                      Other (positive)  \\\n",
       "16     could be the tool that a handicapped person ...   \n",
       "115  Criminal Investigation Lesser Crimes     diffe...   \n",
       "125                                                      \n",
       "162                           robotic immortality        \n",
       "275        science and technology development suppo...   \n",
       "\n",
       "                                   Processed_Paragraph     Sentiment_Type  \\\n",
       "16   [robot, must, keyed, single, individuals, voic...  Cyborg (positive)   \n",
       "115  [fbi, enthusiastic, big, floyd, whose, namesak...  Cyborg (positive)   \n",
       "125  [condor, hand, tries, amusing, after, hero, se...  Cyborg (positive)   \n",
       "162  [tomorrow, makers, grant, macmillan, volume, d...  Cyborg (positive)   \n",
       "275  [computer, scientist, john, mccarthy, coined, ...  Cyborg (positive)   \n",
       "\n",
       "     Sentiment_Value  \n",
       "16                 2  \n",
       "115                1  \n",
       "125                1  \n",
       "162                2  \n",
       "275                1  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the sentiment columns into rows creating a new row for each sentiment that has a non-zero entry\n",
    "data_melt = pd.melt(data, id_vars=remaining_columns, value_vars=positive_columns + negative_columns, var_name='Sentiment_Type', value_name='Sentiment_Value')\n",
    "\n",
    "# drop zero entries from 'Value' column\n",
    "data_melt_nonzero = data_melt[data_melt['Sentiment_Value'] != 0]\n",
    "# Preview pivotted nonzero table\n",
    "data_melt_nonzero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_Value\n",
       "12    5\n",
       "9     4\n",
       "10    4\n",
       "13    3\n",
       "16    2\n",
       "15    2\n",
       "19    1\n",
       "11    1\n",
       "18    1\n",
       "14    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_melt_nonzero['Sentiment_Value'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39653</th>\n",
       "      <td>54626c6e79881072f4f730ac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science</td>\n",
       "      <td>Warfare is increasingly guided by software. To...</td>\n",
       "      <td>Fearing Bombs That Can Pick Whom to Kill</td>\n",
       "      <td>0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>4.833333</td>\n",
       "      <td></td>\n",
       "      <td>warfare</td>\n",
       "      <td>[warfare, increasingly, guided, software, toda...</td>\n",
       "      <td>Military (negative)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Article ID Article Date NYT section  \\\n",
       "39653  54626c6e79881072f4f730ac          NaN     Science   \n",
       "\n",
       "                                               Paragraph  \\\n",
       "39653  Warfare is increasingly guided by software. To...   \n",
       "\n",
       "                                          Title  Fiction   AI Mood  \\\n",
       "39653  Fearing Bombs That Can Pick Whom to Kill        0  2.444444   \n",
       "\n",
       "       AI Relevance   Other (negative)          Other (positive)  \\\n",
       "39653      4.833333                     warfare                    \n",
       "\n",
       "                                     Processed_Paragraph       Sentiment_Type  \\\n",
       "39653  [warfare, increasingly, guided, software, toda...  Military (negative)   \n",
       "\n",
       "       Sentiment_Value  \n",
       "39653               14  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The article with a sentiment 'Value' of 14 is heavily associated with 'Military (negative)'\n",
    "data_melt_nonzero[data_melt_nonzero['Sentiment_Value'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create word count dataframe with 'Article ID', 'Article Date', 'Word', 'Count', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', 'Sentiment (Positive/Negative)', 'Value'\n",
    "# word_count_df = pd.DataFrame(columns=['Article ID', 'Article Date', 'Word', 'Count', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', 'Sentiment (Positive/Negative)', 'Value'])\n",
    "\n",
    "\n",
    "# expand 'Processed_Paragraph' column list entries into a row for each word\n",
    "data_word_expand = data_melt_nonzero.explode('Processed_Paragraph')\n",
    "# reset index\n",
    "data_word_expand.reset_index(drop=True, inplace=True)\n",
    "# rename 'Processed_Paragraph' column to 'Word'\n",
    "data_word_expand.rename(columns={'Processed_Paragraph': 'Word'}, inplace=True)\n",
    "# drop rows with NaN values\n",
    "# data_word_expand.dropna(inplace=True)\n",
    "# add count value from positive_word_counts and negative_word_counts to data_word_expand dataframe for each word and sentiment type\n",
    "data_word_expand['Count'] = data_word_expand.apply(lambda row: positive_word_counts[row['Word']] if row['Sentiment_Type'] in positive_columns else negative_word_counts[row['Word']], axis=1)\n",
    "# reset index\n",
    "data_word_expand.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455138, 14)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_word_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Article ID', 'Article Date', 'NYT section', 'Paragraph', 'Title', 'Fiction', 'AI Mood', 'AI Relevance', 'Other (negative)', 'Other (positive)', 'Word', 'Sentiment_Type', 'Sentiment_Value', 'Count',\n"
     ]
    }
   ],
   "source": [
    "# print columns of data_word_expand in single line with '' around col name\n",
    "print(' '.join([f\"'{col}',\" for col in data_word_expand.columns.tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>must</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>keyed</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>single</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>individuals</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID   AI Mood  AI Relevance         Word  \\\n",
       "0  4fd156a18eb7c8105d63aed2  4.333333           5.0        robot   \n",
       "1  4fd156a18eb7c8105d63aed2  4.333333           5.0         must   \n",
       "2  4fd156a18eb7c8105d63aed2  4.333333           5.0        keyed   \n",
       "3  4fd156a18eb7c8105d63aed2  4.333333           5.0       single   \n",
       "4  4fd156a18eb7c8105d63aed2  4.333333           5.0  individuals   \n",
       "\n",
       "      Sentiment_Type  Sentiment_Value  Count  \n",
       "0  Cyborg (positive)                2   2149  \n",
       "1  Cyborg (positive)                2     65  \n",
       "2  Cyborg (positive)                2      1  \n",
       "3  Cyborg (positive)                2     25  \n",
       "4  Cyborg (positive)                2      9  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns in data_word_expand - only keep 'Article ID', 'Word' 'Sentiment_Type', 'AI Mood', 'Sentiment_Value', 'AI Relevance', 'Count'\n",
    "data_word_expand_opt = data_word_expand.drop(['Article Date', 'NYT section', 'Paragraph', 'Title', 'Fiction', 'Other (negative)', 'Other (positive)'], axis=1) # 'Article Year'\n",
    "\n",
    "data_word_expand_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>must</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>keyed</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>single</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>individuals</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID   AI Mood  AI Relevance         Word  \\\n",
       "0  4fd156a18eb7c8105d63aed2  4.333333           5.0        robot   \n",
       "1  4fd156a18eb7c8105d63aed2  4.333333           5.0         must   \n",
       "2  4fd156a18eb7c8105d63aed2  4.333333           5.0        keyed   \n",
       "3  4fd156a18eb7c8105d63aed2  4.333333           5.0       single   \n",
       "4  4fd156a18eb7c8105d63aed2  4.333333           5.0  individuals   \n",
       "\n",
       "  Sentiment_Type  Sentiment_Value  Count  \n",
       "0       positive                2   2149  \n",
       "1       positive                2     65  \n",
       "2       positive                2      1  \n",
       "3       positive                2     25  \n",
       "4       positive                2      9  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df that keeps just the 'positive' or 'negative' within the parenthesis of the 'Sentiment_Type' column\n",
    "data_word_pos_neg = data_word_expand_opt.copy()\n",
    "data_word_pos_neg['Sentiment_Type'] = data_word_pos_neg['Sentiment_Type'].str.extract(r'\\((.*?)\\)')\n",
    "\n",
    "data_word_pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>4fd24ceb8eb7c8105d7ece3b</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.638889</td>\n",
       "      <td>AI</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>4fd24ceb8eb7c8105d7ece3b</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.638889</td>\n",
       "      <td>AI</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>4fd24ceb8eb7c8105d7ece3b</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.638889</td>\n",
       "      <td>AI</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>4fd24ceb8eb7c8105d7ece3b</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.638889</td>\n",
       "      <td>AI</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>4fd24d6b8eb7c8105d7ee41d</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>AI</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454650</th>\n",
       "      <td>568a04687988103a8dd337e6</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>AI</td>\n",
       "      <td>negative</td>\n",
       "      <td>13</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454679</th>\n",
       "      <td>568a04687988103a8dd337e6</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>AI</td>\n",
       "      <td>negative</td>\n",
       "      <td>13</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454869</th>\n",
       "      <td>5718b2ba7988102ed807b6e4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>AI</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455018</th>\n",
       "      <td>5718b2ba7988102ed807b6e4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>AI</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455057</th>\n",
       "      <td>5718b2ba7988102ed807b6e4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>AI</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Article ID   AI Mood  AI Relevance Word Sentiment_Type  \\\n",
       "3905    4fd24ceb8eb7c8105d7ece3b  3.250000      4.638889   AI       positive   \n",
       "3913    4fd24ceb8eb7c8105d7ece3b  3.250000      4.638889   AI       positive   \n",
       "3972    4fd24ceb8eb7c8105d7ece3b  3.250000      4.638889   AI       positive   \n",
       "4041    4fd24ceb8eb7c8105d7ece3b  3.250000      4.638889   AI       positive   \n",
       "4230    4fd24d6b8eb7c8105d7ee41d  3.533333      4.533333   AI       positive   \n",
       "...                          ...       ...           ...  ...            ...   \n",
       "454650  568a04687988103a8dd337e6  2.666667      4.750000   AI       negative   \n",
       "454679  568a04687988103a8dd337e6  2.666667      4.750000   AI       negative   \n",
       "454869  5718b2ba7988102ed807b6e4  2.666667      4.400000   AI       negative   \n",
       "455018  5718b2ba7988102ed807b6e4  2.666667      4.400000   AI       negative   \n",
       "455057  5718b2ba7988102ed807b6e4  2.666667      4.400000   AI       negative   \n",
       "\n",
       "        Sentiment_Value  Count  \n",
       "3905                  1    490  \n",
       "3913                  1    490  \n",
       "3972                  1    490  \n",
       "4041                  1    490  \n",
       "4230                  1    490  \n",
       "...                 ...    ...  \n",
       "454650               13    365  \n",
       "454679               13    365  \n",
       "454869                1    365  \n",
       "455018                1    365  \n",
       "455057                1    365  \n",
       "\n",
       "[2417 rows x 7 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_word_pos_neg[data_word_pos_neg['Word'] == 'AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215208</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172992</th>\n",
       "      <td>4fd14a688eb7c8105d627e17</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239943</th>\n",
       "      <td>4fd14a688eb7c8105d627e17</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215246</th>\n",
       "      <td>4fd14a688eb7c8105d627e17</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215336</th>\n",
       "      <td>4fd155958eb7c8105d639695</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215273</th>\n",
       "      <td>4fd155958eb7c8105d639695</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215307</th>\n",
       "      <td>4fd155958eb7c8105d639695</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451</th>\n",
       "      <td>4fd1559c8eb7c8105d639bc6</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Article ID   AI Mood  AI Relevance   Word  \\\n",
       "215208  4fd14a678eb7c8105d627d35  3.000000      3.333333  robot   \n",
       "172992  4fd14a688eb7c8105d627e17  4.000000      3.666667  robot   \n",
       "239943  4fd14a688eb7c8105d627e17  4.000000      3.666667  robot   \n",
       "215246  4fd14a688eb7c8105d627e17  4.000000      3.666667  robot   \n",
       "215336  4fd155958eb7c8105d639695  3.111111      3.444444  robot   \n",
       "215273  4fd155958eb7c8105d639695  3.111111      3.444444  robot   \n",
       "215307  4fd155958eb7c8105d639695  3.111111      3.444444  robot   \n",
       "27451   4fd1559c8eb7c8105d639bc6  3.333333      4.666667  robot   \n",
       "\n",
       "       Sentiment_Type  Sentiment_Value  Count  \n",
       "215208       positive                1   2149  \n",
       "172992       positive                1   2149  \n",
       "239943       positive                1   2149  \n",
       "215246       positive                1   2149  \n",
       "215336       positive                2   2149  \n",
       "215273       positive                2   2149  \n",
       "215307       positive                2   2149  \n",
       "27451        positive                1   2149  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows with 'Word' == 'robot' and sort by 'Article ID' \n",
    "data_word_pos_neg[data_word_pos_neg['Word'] == 'robot'].sort_values(by=['Article ID']).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>aircraft</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>aircraft</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>amok</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>amok</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>artificial</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1187</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID        Word Sentiment_Type   AI Mood  \\\n",
       "0  4fd100e88eb7c8105d5bbd2d    aircraft       negative  2.333333   \n",
       "1  4fd100e88eb7c8105d5bbd2d    aircraft       positive  2.333333   \n",
       "2  4fd100e88eb7c8105d5bbd2d        amok       negative  2.333333   \n",
       "3  4fd100e88eb7c8105d5bbd2d        amok       positive  2.333333   \n",
       "4  4fd100e88eb7c8105d5bbd2d  artificial       negative  2.333333   \n",
       "\n",
       "   AI Relevance  Count  Sentiment_Value  \n",
       "0           5.0     16                5  \n",
       "1           5.0     20                1  \n",
       "2           5.0      5                5  \n",
       "3           5.0      3                1  \n",
       "4           5.0   1187                5  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate data_word_pos_neg by 'Article ID', 'Word', and 'Sentiment_Type' taking the first value of 'AI Mood', 'AI Relevance' and 'Count' and summing 'Sentiment_Value'\n",
    "data_word_pos_neg_agg = data_word_pos_neg.groupby(['Article ID', 'Word', 'Sentiment_Type']).agg({'AI Mood': 'first', 'AI Relevance': 'first', 'Count': 'first', 'Sentiment_Value': 'sum'}).reset_index()\n",
    "\n",
    "data_word_pos_neg_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15195\n",
      "['aircraft' 'amok' 'artificial' ... 'commissioner' 'fiduciary' 'kara']\n"
     ]
    }
   ],
   "source": [
    "# print each unique value of 'Word' in data_word_pos_neg_agg\n",
    "print(len(data_word_pos_neg_agg['Word'].unique()))\n",
    "print(data_word_pos_neg_agg['Word'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137722, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>4fd14a688eb7c8105d627e17</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>4fd155958eb7c8105d639695</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>2149</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>4fd1559c8eb7c8105d639bc6</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2149</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4fd155f98eb7c8105d639daa</td>\n",
       "      <td>robot</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>4fd155f98eb7c8105d639daa</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4fd156548eb7c8105d63aa5b</td>\n",
       "      <td>robot</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>4fd156558eb7c8105d63ab15</td>\n",
       "      <td>robot</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Article ID   Word Sentiment_Type   AI Mood  AI Relevance  \\\n",
       "131  4fd14a678eb7c8105d627d35  robot       positive  3.000000      3.333333   \n",
       "167  4fd14a688eb7c8105d627e17  robot       positive  4.000000      3.666667   \n",
       "324  4fd155958eb7c8105d639695  robot       positive  3.111111      3.444444   \n",
       "367  4fd1559c8eb7c8105d639bc6  robot       positive  3.333333      4.666667   \n",
       "433  4fd155f98eb7c8105d639daa  robot       negative  3.666667      4.333333   \n",
       "434  4fd155f98eb7c8105d639daa  robot       positive  3.666667      4.333333   \n",
       "485  4fd156548eb7c8105d63aa5b  robot       negative  2.666667      4.166667   \n",
       "515  4fd156558eb7c8105d63ab15  robot       positive  3.333333      3.333333   \n",
       "\n",
       "     Count  Sentiment_Value  \n",
       "131   2149                1  \n",
       "167   2149                3  \n",
       "324   2149                6  \n",
       "367   2149                2  \n",
       "433    785                2  \n",
       "434   2149                1  \n",
       "485    785                1  \n",
       "515   2149                1  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_word_pos_neg_agg.shape)\n",
    "data_word_pos_neg_agg[data_word_pos_neg_agg['Word'] == 'robot'].sort_values(by=['Article ID']).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>challengers</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>exploded</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>hurled</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4fd14a688eb7c8105d627e36</td>\n",
       "      <td>dime</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.190476</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>4fd14a688eb7c8105d627e36</td>\n",
       "      <td>majors</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.190476</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137700</th>\n",
       "      <td>572350e37988101b346ef18a</td>\n",
       "      <td>fiduciary</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137701</th>\n",
       "      <td>572350e37988101b346ef18a</td>\n",
       "      <td>fiduciary</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137708</th>\n",
       "      <td>572350e37988101b346ef18a</td>\n",
       "      <td>kara</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137709</th>\n",
       "      <td>572350e37988101b346ef18a</td>\n",
       "      <td>kara</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137718</th>\n",
       "      <td>572350e37988101b346ef18a</td>\n",
       "      <td>stein</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9188 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Article ID         Word Sentiment_Type   AI Mood  \\\n",
       "118     4fd14a678eb7c8105d627d35  challengers       positive  3.000000   \n",
       "121     4fd14a678eb7c8105d627d35     exploded       positive  3.000000   \n",
       "122     4fd14a678eb7c8105d627d35       hurled       positive  3.000000   \n",
       "198     4fd14a688eb7c8105d627e36         dime       positive  3.190476   \n",
       "225     4fd14a688eb7c8105d627e36       majors       positive  3.190476   \n",
       "...                          ...          ...            ...       ...   \n",
       "137700  572350e37988101b346ef18a    fiduciary       negative  2.666667   \n",
       "137701  572350e37988101b346ef18a    fiduciary       positive  2.666667   \n",
       "137708  572350e37988101b346ef18a         kara       negative  2.666667   \n",
       "137709  572350e37988101b346ef18a         kara       positive  2.666667   \n",
       "137718  572350e37988101b346ef18a        stein       negative  2.666667   \n",
       "\n",
       "        AI Relevance  Count  Sentiment_Value  \n",
       "118         3.333333      1                1  \n",
       "121         3.333333      1                1  \n",
       "122         3.333333      1                1  \n",
       "198         3.809524      1                4  \n",
       "225         3.809524      1                4  \n",
       "...              ...    ...              ...  \n",
       "137700      4.000000      1                1  \n",
       "137701      4.000000      1                2  \n",
       "137708      4.000000      1                1  \n",
       "137709      4.000000      1                2  \n",
       "137718      4.000000      1                1  \n",
       "\n",
       "[9188 rows x 7 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview words that only occur once\n",
    "data_word_pos_neg_agg[data_word_pos_neg_agg['Count'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Formatted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pantab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>1986-08-10 00:00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The robot must be keyed to a single individual...</td>\n",
       "      <td>TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>could be the tool that a handicapped person ...</td>\n",
       "      <td>[robot, must, keyed, single, individuals, voic...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4fd16d848eb7c8105d660007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The F.B.I. is enthusiastic about Big Floyd, wh...</td>\n",
       "      <td>'BIG FLOYD' JOINS THE FORCE</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>Criminal Investigation Lesser Crimes     diffe...</td>\n",
       "      <td>[fbi, enthusiastic, big, floyd, whose, namesak...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4fd1707b8eb7c8105d66317b</td>\n",
       "      <td>1986-08-10 00:00:00</td>\n",
       "      <td>Arts</td>\n",
       "      <td>''Condor,'' on the other hand, tries to be amu...</td>\n",
       "      <td>WHEN THE SLUSH PILE COMES TO LIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[condor, hand, tries, amusing, after, hero, se...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4fd1781e8eb7c8105d66ef93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>''The Tomorrow Makers,'' by Grant Fjermedal ($...</td>\n",
       "      <td>HOW TO AVOID TUNNEL VISION</td>\n",
       "      <td>0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>AI minds are wildly different from hum...</td>\n",
       "      <td>robotic immortality</td>\n",
       "      <td>[tomorrow, makers, grant, macmillan, volume, d...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4fd190318eb7c8105d696da7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology; Science; Week in Review</td>\n",
       "      <td>WHEN the computer scientist John McCarthy coin...</td>\n",
       "      <td>IDEAS AND TRENDS: Can Machines Learn to Think?...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>AI companies failing</td>\n",
       "      <td>science and technology development suppo...</td>\n",
       "      <td>[computer, scientist, john, mccarthy, coined, ...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Article ID         Article Date  \\\n",
       "16   4fd156a18eb7c8105d63aed2  1986-08-10 00:00:00   \n",
       "115  4fd16d848eb7c8105d660007                  NaN   \n",
       "125  4fd1707b8eb7c8105d66317b  1986-08-10 00:00:00   \n",
       "162  4fd1781e8eb7c8105d66ef93                  NaN   \n",
       "275  4fd190318eb7c8105d696da7                  NaN   \n",
       "\n",
       "                             NYT section  \\\n",
       "16                                  U.S.   \n",
       "115                                 U.S.   \n",
       "125                                 Arts   \n",
       "162                             Business   \n",
       "275  Technology; Science; Week in Review   \n",
       "\n",
       "                                             Paragraph  \\\n",
       "16   The robot must be keyed to a single individual...   \n",
       "115  The F.B.I. is enthusiastic about Big Floyd, wh...   \n",
       "125  ''Condor,'' on the other hand, tries to be amu...   \n",
       "162  ''The Tomorrow Makers,'' by Grant Fjermedal ($...   \n",
       "275  WHEN the computer scientist John McCarthy coin...   \n",
       "\n",
       "                                                 Title  Fiction   AI Mood  \\\n",
       "16        TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR        0  4.333333   \n",
       "115                        'BIG FLOYD' JOINS THE FORCE        0  3.666667   \n",
       "125                  WHEN THE SLUSH PILE COMES TO LIFE        1  3.000000   \n",
       "162                         HOW TO AVOID TUNNEL VISION        0  3.111111   \n",
       "275  IDEAS AND TRENDS: Can Machines Learn to Think?...        0  2.888889   \n",
       "\n",
       "     AI Relevance                                   Other (negative)  \\\n",
       "16       5.000000                                                      \n",
       "115      5.000000                                                      \n",
       "125      3.333333                                                      \n",
       "162      4.666667          AI minds are wildly different from hum...   \n",
       "275      4.555556                           AI companies failing       \n",
       "\n",
       "                                      Other (positive)  \\\n",
       "16     could be the tool that a handicapped person ...   \n",
       "115  Criminal Investigation Lesser Crimes     diffe...   \n",
       "125                                                      \n",
       "162                           robotic immortality        \n",
       "275        science and technology development suppo...   \n",
       "\n",
       "                                   Processed_Paragraph     Sentiment_Type  \\\n",
       "16   [robot, must, keyed, single, individuals, voic...  Cyborg (positive)   \n",
       "115  [fbi, enthusiastic, big, floyd, whose, namesak...  Cyborg (positive)   \n",
       "125  [condor, hand, tries, amusing, after, hero, se...  Cyborg (positive)   \n",
       "162  [tomorrow, makers, grant, macmillan, volume, d...  Cyborg (positive)   \n",
       "275  [computer, scientist, john, mccarthy, coined, ...  Cyborg (positive)   \n",
       "\n",
       "     Sentiment_Value  \n",
       "16                 2  \n",
       "115                1  \n",
       "125                1  \n",
       "162                2  \n",
       "275                1  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove ' UTC' from 'Article Date' column in data_melt_nonzero\n",
    "data_melt_nonzero.loc[:, 'Article Date'] = data_melt_nonzero['Article Date'].str.replace(' UTC', '')\n",
    "\n",
    "data_melt_nonzero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to 'data/ai_concat_pivot.csv'\n",
    "data_melt_nonzero_opt = data_melt_nonzero.drop(['Processed_Paragraph'], axis=1)\n",
    "data_melt_nonzero_opt.to_csv('data/ai_concat_pivot.csv', index=False)\n",
    "# output to .hyper file\n",
    "pantab.frame_to_hyper(data_melt_nonzero_opt, 'data/ai_concat_pivot.hyper', table='ai_concat_pivot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to CSV\n",
    "data_word_pos_neg_agg.to_csv('data/data_concat_words_pos_neg.csv', index=False)\n",
    "# save as .hyper file\n",
    "pantab.frame_to_hyper(data_word_pos_neg_agg, 'data/data_concat_words_pos_neg.hyper', table='data_concat_words_pos_neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_word_expand_opt.to_csv('data/data_concat_word_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
