{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import string\n",
    "# Importing nltk resources for text preprocessing\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Cyborg (positive)</th>\n",
       "      <th>Decisions (positive)</th>\n",
       "      <th>Education (positive)</th>\n",
       "      <th>Entertain (positive)</th>\n",
       "      <th>...</th>\n",
       "      <th>Cyborg (negative)</th>\n",
       "      <th>Ethics (negative)</th>\n",
       "      <th>Military (negative)</th>\n",
       "      <th>Progress (negative)</th>\n",
       "      <th>Singularity (negative)</th>\n",
       "      <th>Work (negative)</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd100e58eb7c8105d5bbb33</td>\n",
       "      <td>2012-04-01 00:00:00 UTC</td>\n",
       "      <td>Arts; Style; Magazine</td>\n",
       "      <td>9. The robot designs woven into these tea towe...</td>\n",
       "      <td>Stijl Council</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science; Health</td>\n",
       "      <td>In 1818, Mary Shelley's ''Frankenstein'' raise...</td>\n",
       "      <td>Statues to Golems to R2-D2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd14a668eb7c8105d627c40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business; Opinion</td>\n",
       "      <td>Mr. Culbertson would use ''powerful new tools'...</td>\n",
       "      <td>ECONOMIC POLICY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td></td>\n",
       "      <td>manage entire economies AI and computers could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd14a678eb7c8105d627d24</td>\n",
       "      <td>1986-02-16 00:00:00 UTC</td>\n",
       "      <td>Business</td>\n",
       "      <td>Some golfer. Fortunately, you'll never have to...</td>\n",
       "      <td>IN PURSUIT OF THE PERFECT GOLF BALL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>1986-02-16 00:00:00 UTC</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>All week long Navy divers and salvage experts ...</td>\n",
       "      <td>LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID             Article Date            NYT section  \\\n",
       "0  4fd100e58eb7c8105d5bbb33  2012-04-01 00:00:00 UTC  Arts; Style; Magazine   \n",
       "1  4fd100e88eb7c8105d5bbd2d                      NaN        Science; Health   \n",
       "2  4fd14a668eb7c8105d627c40                      NaN      Business; Opinion   \n",
       "3  4fd14a678eb7c8105d627d24  1986-02-16 00:00:00 UTC               Business   \n",
       "4  4fd14a678eb7c8105d627d35  1986-02-16 00:00:00 UTC                   U.S.   \n",
       "\n",
       "                                           Paragraph  \\\n",
       "0  9. The robot designs woven into these tea towe...   \n",
       "1  In 1818, Mary Shelley's ''Frankenstein'' raise...   \n",
       "2  Mr. Culbertson would use ''powerful new tools'...   \n",
       "3  Some golfer. Fortunately, you'll never have to...   \n",
       "4  All week long Navy divers and salvage experts ...   \n",
       "\n",
       "                                               Title  Fiction  \\\n",
       "0                                      Stijl Council        0   \n",
       "1                         Statues to Golems to R2-D2        2   \n",
       "2                                    ECONOMIC POLICY        0   \n",
       "3                IN PURSUIT OF THE PERFECT GOLF BALL        0   \n",
       "4  LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...        0   \n",
       "\n",
       "   Cyborg (positive)  Decisions (positive)  Education (positive)  \\\n",
       "0                  0                     0                     0   \n",
       "1                  0                     0                     0   \n",
       "2                  0                     2                     0   \n",
       "3                  0                     0                     0   \n",
       "4                  0                     0                     0   \n",
       "\n",
       "   Entertain (positive)  ...  Cyborg (negative)  Ethics (negative)  \\\n",
       "0                     0  ...                  0                  0   \n",
       "1                     0  ...                  0                  1   \n",
       "2                     0  ...                  0                  0   \n",
       "3                     0  ...                  0                  0   \n",
       "4                     0  ...                  0                  0   \n",
       "\n",
       "   Military (negative)  Progress (negative)  Singularity (negative)  \\\n",
       "0                    0                    0                       0   \n",
       "1                    2                    0                       1   \n",
       "2                    0                    0                       0   \n",
       "3                    0                    0                       0   \n",
       "4                    0                    0                       0   \n",
       "\n",
       "   Work (negative)   AI Mood  AI Relevance  Other (negative)  \\\n",
       "0                0  3.000000      2.333333                     \n",
       "1                0  2.333333      5.000000                     \n",
       "2                0  4.000000      4.333333                     \n",
       "3                0  3.000000      4.000000                     \n",
       "4                0  3.000000      3.333333                     \n",
       "\n",
       "                                    Other (positive)  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  manage entire economies AI and computers could...  \n",
       "3                                                     \n",
       "4                                                     \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data/ai-perception-concat-paragraphs.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# display first 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3365\n",
      "Number of NaNs in 'Article Date' column:  1418 (42.14%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows:\", data.shape[0])\n",
    "# Count NaNs in 'Article Date' column\n",
    "print(\"Number of NaNs in 'Article Date' column: \", data['Article Date'].isnull().sum(), f\"({round(data['Article Date'].isnull().sum()/data.shape[0]*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Cyborg (positive)</th>\n",
       "      <th>Decisions (positive)</th>\n",
       "      <th>Education (positive)</th>\n",
       "      <th>Entertain (positive)</th>\n",
       "      <th>...</th>\n",
       "      <th>Military (negative)</th>\n",
       "      <th>Progress (negative)</th>\n",
       "      <th>Singularity (negative)</th>\n",
       "      <th>Work (negative)</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Article Year</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd100e58eb7c8105d5bbb33</td>\n",
       "      <td>2012-04-01 00:00:00+00:00</td>\n",
       "      <td>Arts; Style; Magazine</td>\n",
       "      <td>9. The robot designs woven into these tea towe...</td>\n",
       "      <td>Stijl Council</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012</td>\n",
       "      <td>[9, robot, designs, woven, into, these, tea, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd100e88eb7c8105d5bbd2d</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Science; Health</td>\n",
       "      <td>In 1818, Mary Shelley's ''Frankenstein'' raise...</td>\n",
       "      <td>Statues to Golems to R2-D2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[1818, mary, frankenstein, raised, specter, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd14a668eb7c8105d627c40</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Business; Opinion</td>\n",
       "      <td>Mr. Culbertson would use ''powerful new tools'...</td>\n",
       "      <td>ECONOMIC POLICY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td></td>\n",
       "      <td>manage entire economies AI and computers could...</td>\n",
       "      <td>0</td>\n",
       "      <td>[culbertson, powerful, tools, model, manage, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd14a678eb7c8105d627d24</td>\n",
       "      <td>1986-02-16 00:00:00+00:00</td>\n",
       "      <td>Business</td>\n",
       "      <td>Some golfer. Fortunately, you'll never have to...</td>\n",
       "      <td>IN PURSUIT OF THE PERFECT GOLF BALL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1986</td>\n",
       "      <td>[some, golfer, fortunately, youll, never, meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd14a678eb7c8105d627d35</td>\n",
       "      <td>1986-02-16 00:00:00+00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>All week long Navy divers and salvage experts ...</td>\n",
       "      <td>LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1986</td>\n",
       "      <td>[week, long, navy, divers, salvage, experts, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID              Article Date            NYT section  \\\n",
       "0  4fd100e58eb7c8105d5bbb33 2012-04-01 00:00:00+00:00  Arts; Style; Magazine   \n",
       "1  4fd100e88eb7c8105d5bbd2d                       NaT        Science; Health   \n",
       "2  4fd14a668eb7c8105d627c40                       NaT      Business; Opinion   \n",
       "3  4fd14a678eb7c8105d627d24 1986-02-16 00:00:00+00:00               Business   \n",
       "4  4fd14a678eb7c8105d627d35 1986-02-16 00:00:00+00:00                   U.S.   \n",
       "\n",
       "                                           Paragraph  \\\n",
       "0  9. The robot designs woven into these tea towe...   \n",
       "1  In 1818, Mary Shelley's ''Frankenstein'' raise...   \n",
       "2  Mr. Culbertson would use ''powerful new tools'...   \n",
       "3  Some golfer. Fortunately, you'll never have to...   \n",
       "4  All week long Navy divers and salvage experts ...   \n",
       "\n",
       "                                               Title  Fiction  \\\n",
       "0                                      Stijl Council        0   \n",
       "1                         Statues to Golems to R2-D2        2   \n",
       "2                                    ECONOMIC POLICY        0   \n",
       "3                IN PURSUIT OF THE PERFECT GOLF BALL        0   \n",
       "4  LATEST PICTURES FROM NASA SHOW WODER FIRE ON B...        0   \n",
       "\n",
       "   Cyborg (positive)  Decisions (positive)  Education (positive)  \\\n",
       "0                  0                     0                     0   \n",
       "1                  0                     0                     0   \n",
       "2                  0                     2                     0   \n",
       "3                  0                     0                     0   \n",
       "4                  0                     0                     0   \n",
       "\n",
       "   Entertain (positive)  ...  Military (negative)  Progress (negative)  \\\n",
       "0                     0  ...                    0                    0   \n",
       "1                     0  ...                    2                    0   \n",
       "2                     0  ...                    0                    0   \n",
       "3                     0  ...                    0                    0   \n",
       "4                     0  ...                    0                    0   \n",
       "\n",
       "   Singularity (negative)  Work (negative)   AI Mood  AI Relevance  \\\n",
       "0                       0                0  3.000000      2.333333   \n",
       "1                       1                0  2.333333      5.000000   \n",
       "2                       0                0  4.000000      4.333333   \n",
       "3                       0                0  3.000000      4.000000   \n",
       "4                       0                0  3.000000      3.333333   \n",
       "\n",
       "   Other (negative)                                   Other (positive)  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                    manage entire economies AI and computers could...   \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "\n",
       "   Article Year                                Processed_Paragraph  \n",
       "0          2012  [9, robot, designs, woven, into, these, tea, t...  \n",
       "1             0  [1818, mary, frankenstein, raised, specter, ma...  \n",
       "2             0  [culbertson, powerful, tools, model, manage, e...  \n",
       "3          1986  [some, golfer, fortunately, youll, never, meet...  \n",
       "4          1986  [week, long, navy, divers, salvage, experts, u...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change 'Article Date' in datetime64[ns, UTC] format and change to 'Article Year' in int64 format\n",
    "# Convert the 'Article Date' column to datetime, coercing errors\n",
    "data['Article Date'] = pd.to_datetime(data['Article Date'], errors='coerce')\n",
    "data['Article Year'] = data['Article Date'].dt.year\n",
    "# convert to int64 - ignore nulls\n",
    "data['Article Year'] = data['Article Year'].fillna(0)\n",
    "data['Article Year'] = data['Article Year'].astype('int64')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common English stop words - set class data type\n",
    "stop_words = {'thus', 'the', 'and', 'to', 'of', 'a', 'in', 'that', 'is', 'was', 'he', 'for', 'it', 'with', 'as', 'his', 'on', 'be', 'at', 'by', 'i', 'this', 'had', 'not', 'but', 'from', 'or', 'have', 'an', 'they', 'which', 'you', 'were', 'her', 'their', 'we', 'its', 'said', 'like', 'â€”', 'â€”â€”', '-', '--'}\n",
    "\n",
    "# load frequent words dataset - columns are 'word' and 'count'\n",
    "freq_words = pd.read_csv('data/unigram_freq.csv')\n",
    "\n",
    "# add 1 and 2 letter words to the stop_words set if they are not already there\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if len(word) <= 2:\n",
    "        stop_words.add(word)\n",
    "\n",
    "# add stop words with count more than 550,000,000\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if freq_words['count'][i] > 550000000:\n",
    "        stop_words.add(word)\n",
    "\n",
    "# create pandas series with words with count less than 100,000\n",
    "less_freq_words = freq_words[freq_words['count'] < 100000]['word'].tail(100000).tolist()\n",
    "# add less_freq_words to stop_words set\n",
    "stop_words = stop_words.union(set(less_freq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233846, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freq_words[freq_words['count'] > 550000000].shape\n",
    "freq_words[freq_words['count'] < 100000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100774\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text (split by spaces and remove punctuation)\n",
    "def custom_tokenize(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize by spaces\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Updated function to preprocess text (tokenize and remove stop words) with handling for missing or non-string values\n",
    "def custom_preprocess_text(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = custom_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9. The robot designs woven into these tea towe...</td>\n",
       "      <td>[9, robot, designs, woven, into, these, tea, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 1818, Mary Shelley's ''Frankenstein'' raise...</td>\n",
       "      <td>[1818, mary, frankenstein, raised, specter, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Culbertson would use ''powerful new tools'...</td>\n",
       "      <td>[culbertson, powerful, tools, model, manage, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some golfer. Fortunately, you'll never have to...</td>\n",
       "      <td>[some, golfer, fortunately, youll, never, meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All week long Navy divers and salvage experts ...</td>\n",
       "      <td>[week, long, navy, divers, salvage, experts, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Paragraph  \\\n",
       "0  9. The robot designs woven into these tea towe...   \n",
       "1  In 1818, Mary Shelley's ''Frankenstein'' raise...   \n",
       "2  Mr. Culbertson would use ''powerful new tools'...   \n",
       "3  Some golfer. Fortunately, you'll never have to...   \n",
       "4  All week long Navy divers and salvage experts ...   \n",
       "\n",
       "                                 Processed_Paragraph  \n",
       "0  [9, robot, designs, woven, into, these, tea, t...  \n",
       "1  [1818, mary, frankenstein, raised, specter, ma...  \n",
       "2  [culbertson, powerful, tools, model, manage, e...  \n",
       "3  [some, golfer, fortunately, youll, never, meet...  \n",
       "4  [week, long, navy, divers, salvage, experts, u...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the custom preprocessing function to the 'Paragraph' column\n",
    "data['Processed_Paragraph'] = data['Paragraph'].apply(custom_preprocess_text)\n",
    "\n",
    "# Preview the processed paragraphs of the first few rows\n",
    "data[['Paragraph', 'Processed_Paragraph']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Word Associations (Positive and Negative)\n",
    "\n",
    "To find words with the most positive and negative associations, we analyze the processed paragraphs in conjunction with the positive and negative columns in the dataset. We create functions to aggregate the word counts based on these associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns representing positive and negative associations\n",
    "positive_columns = ['Cyborg (positive)', 'Decisions (positive)', 'Education (positive)', 'Entertain (positive)', 'Healthcare (positive)', 'Singularity (positive)', 'Transportation (positive)', 'Work (positive)']\n",
    "negative_columns = ['Controling AI (negative)', 'Cyborg (negative)', 'Ethics (negative)', 'Military (negative)', 'Progress (negative)', 'Singularity (negative)', 'Work (negative)']\n",
    "# \n",
    "\n",
    "# Define remaining columns\n",
    "all_columns = data.columns.tolist()\n",
    "remaining_columns = [col for col in all_columns if col not in positive_columns and col not in negative_columns]\n",
    "\n",
    "# Function to count words with positive and negative associations\n",
    "def count_associations(row):\n",
    "    # Extract processed paragraph\n",
    "    words = row['Processed_Paragraph']\n",
    "    # Initialize counters for positive and negative associations\n",
    "    positive_counter = Counter()\n",
    "    negative_counter = Counter()\n",
    "    # Iterate through words and update counters based on associations in the row\n",
    "    for word in words:\n",
    "        if any(row[col] > 0 for col in positive_columns):\n",
    "            positive_counter[word] += 1\n",
    "        if any(row[col] > 0 for col in negative_columns):\n",
    "            negative_counter[word] += 1\n",
    "    return positive_counter, negative_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to count word associations\n",
    "positive_word_counts = Counter()\n",
    "negative_word_counts = Counter()\n",
    "# Create word count dataframe with 'Article ID', 'Article Date', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', '\n",
    "for _, row in data.iterrows():\n",
    "    positive, negative = count_associations(row)\n",
    "    positive_word_counts += positive\n",
    "    negative_word_counts += negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot (positive): 2084\n",
      "robot (negative): 745\n"
     ]
    }
   ],
   "source": [
    "print('robot (positive):', positive_word_counts['robot'])\n",
    "print('robot (negative):', negative_word_counts['robot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive word count: 20225\n",
      "negative word count: 13521\n"
     ]
    }
   ],
   "source": [
    "# print length of positive_word_counts and negative_word_counts dictionaries\n",
    "print('positive word count:', len(positive_word_counts))\n",
    "print('negative word count:', len(negative_word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot in positive words: True \n",
      "robot in negative words: True\n",
      "robot (positive): 2084\n",
      "robot (negative): 745\n"
     ]
    }
   ],
   "source": [
    "# check if 'robot' is contained in negative_word_counts\n",
    "print('robot in positive words:', 'robot' in positive_word_counts, '\\nrobot in negative words:', 'robot' in negative_word_counts)\n",
    "\n",
    "print('robot (positive):', positive_word_counts['robot'])\n",
    "print('robot (negative):', negative_word_counts['robot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check top positively and negatively associated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive: [('robot', 2084), ('intelligence', 1891), ('artificial', 1834), ('computer', 641), ('human', 590), ('technology', 552), ('robots', 502), ('could', 482), ('than', 460), ('into', 441)] \n",
      "top negative: [('intelligence', 1220), ('artificial', 1156), ('robot', 745), ('human', 421), ('computer', 381), ('technology', 346), ('robots', 285), ('people', 262), ('could', 260), ('times', 259)]\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 positive and negative words\n",
    "top_positive_words = positive_word_counts.most_common(10)\n",
    "top_negative_words = negative_word_counts.most_common(10)\n",
    "\n",
    "# top_positive_words, top_negative_words\n",
    "print('top positive:', top_positive_words, '\\ntop negative:', top_negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Sentiment Columns into Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Article Year</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>1986-08-10 00:00:00+00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The robot must be keyed to a single individual...</td>\n",
       "      <td>TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>could be the tool that a handicapped person ...</td>\n",
       "      <td>1986</td>\n",
       "      <td>[robot, must, keyed, single, individuals, voic...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4fd16d848eb7c8105d660007</td>\n",
       "      <td>NaT</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The F.B.I. is enthusiastic about Big Floyd, wh...</td>\n",
       "      <td>'BIG FLOYD' JOINS THE FORCE</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>Criminal Investigation Lesser Crimes     diffe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[fbi, enthusiastic, big, floyd, whose, namesak...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4fd1707b8eb7c8105d66317b</td>\n",
       "      <td>1986-08-10 00:00:00+00:00</td>\n",
       "      <td>Arts</td>\n",
       "      <td>''Condor,'' on the other hand, tries to be amu...</td>\n",
       "      <td>WHEN THE SLUSH PILE COMES TO LIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1986</td>\n",
       "      <td>[condor, hand, tries, amusing, after, hero, se...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4fd1781e8eb7c8105d66ef93</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Business</td>\n",
       "      <td>''The Tomorrow Makers,'' by Grant Fjermedal ($...</td>\n",
       "      <td>HOW TO AVOID TUNNEL VISION</td>\n",
       "      <td>0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>AI minds are wildly different from hum...</td>\n",
       "      <td>robotic immortality</td>\n",
       "      <td>0</td>\n",
       "      <td>[tomorrow, makers, grant, fjermedal, 1895, mac...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4fd190318eb7c8105d696da7</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Technology; Science; Week in Review</td>\n",
       "      <td>WHEN the computer scientist John McCarthy coin...</td>\n",
       "      <td>IDEAS AND TRENDS: Can Machines Learn to Think?...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>AI companies failing</td>\n",
       "      <td>science and technology development suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[computer, scientist, john, mccarthy, coined, ...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Article ID              Article Date  \\\n",
       "16   4fd156a18eb7c8105d63aed2 1986-08-10 00:00:00+00:00   \n",
       "115  4fd16d848eb7c8105d660007                       NaT   \n",
       "125  4fd1707b8eb7c8105d66317b 1986-08-10 00:00:00+00:00   \n",
       "162  4fd1781e8eb7c8105d66ef93                       NaT   \n",
       "275  4fd190318eb7c8105d696da7                       NaT   \n",
       "\n",
       "                             NYT section  \\\n",
       "16                                  U.S.   \n",
       "115                                 U.S.   \n",
       "125                                 Arts   \n",
       "162                             Business   \n",
       "275  Technology; Science; Week in Review   \n",
       "\n",
       "                                             Paragraph  \\\n",
       "16   The robot must be keyed to a single individual...   \n",
       "115  The F.B.I. is enthusiastic about Big Floyd, wh...   \n",
       "125  ''Condor,'' on the other hand, tries to be amu...   \n",
       "162  ''The Tomorrow Makers,'' by Grant Fjermedal ($...   \n",
       "275  WHEN the computer scientist John McCarthy coin...   \n",
       "\n",
       "                                                 Title  Fiction   AI Mood  \\\n",
       "16        TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR        0  4.333333   \n",
       "115                        'BIG FLOYD' JOINS THE FORCE        0  3.666667   \n",
       "125                  WHEN THE SLUSH PILE COMES TO LIFE        1  3.000000   \n",
       "162                         HOW TO AVOID TUNNEL VISION        0  3.111111   \n",
       "275  IDEAS AND TRENDS: Can Machines Learn to Think?...        0  2.888889   \n",
       "\n",
       "     AI Relevance                                   Other (negative)  \\\n",
       "16       5.000000                                                      \n",
       "115      5.000000                                                      \n",
       "125      3.333333                                                      \n",
       "162      4.666667          AI minds are wildly different from hum...   \n",
       "275      4.555556                           AI companies failing       \n",
       "\n",
       "                                      Other (positive)  Article Year  \\\n",
       "16     could be the tool that a handicapped person ...          1986   \n",
       "115  Criminal Investigation Lesser Crimes     diffe...             0   \n",
       "125                                                             1986   \n",
       "162                           robotic immortality                  0   \n",
       "275        science and technology development suppo...             0   \n",
       "\n",
       "                                   Processed_Paragraph     Sentiment_Type  \\\n",
       "16   [robot, must, keyed, single, individuals, voic...  Cyborg (positive)   \n",
       "115  [fbi, enthusiastic, big, floyd, whose, namesak...  Cyborg (positive)   \n",
       "125  [condor, hand, tries, amusing, after, hero, se...  Cyborg (positive)   \n",
       "162  [tomorrow, makers, grant, fjermedal, 1895, mac...  Cyborg (positive)   \n",
       "275  [computer, scientist, john, mccarthy, coined, ...  Cyborg (positive)   \n",
       "\n",
       "     Sentiment_Value  \n",
       "16                 2  \n",
       "115                1  \n",
       "125                1  \n",
       "162                2  \n",
       "275                1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the sentiment columns into rows creating a new row for each sentiment that has a non-zero entry\n",
    "data_melt = pd.melt(data, id_vars=remaining_columns, value_vars=positive_columns + negative_columns, var_name='Sentiment_Type', value_name='Sentiment_Value')\n",
    "\n",
    "# drop zero entries from 'Value' column\n",
    "data_melt_nonzero = data_melt[data_melt['Sentiment_Value'] != 0]\n",
    "# Preview pivotted nonzero table\n",
    "data_melt_nonzero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_Value\n",
       "12    5\n",
       "9     4\n",
       "10    4\n",
       "13    3\n",
       "16    2\n",
       "15    2\n",
       "19    1\n",
       "11    1\n",
       "18    1\n",
       "14    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_melt_nonzero['Sentiment_Value'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Article Year</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39653</th>\n",
       "      <td>54626c6e79881072f4f730ac</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Science</td>\n",
       "      <td>Warfare is increasingly guided by software. To...</td>\n",
       "      <td>Fearing Bombs That Can Pick Whom to Kill</td>\n",
       "      <td>0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>4.833333</td>\n",
       "      <td></td>\n",
       "      <td>warfare</td>\n",
       "      <td>0</td>\n",
       "      <td>[warfare, increasingly, guided, software, toda...</td>\n",
       "      <td>Military (negative)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Article ID Article Date NYT section  \\\n",
       "39653  54626c6e79881072f4f730ac          NaT     Science   \n",
       "\n",
       "                                               Paragraph  \\\n",
       "39653  Warfare is increasingly guided by software. To...   \n",
       "\n",
       "                                          Title  Fiction   AI Mood  \\\n",
       "39653  Fearing Bombs That Can Pick Whom to Kill        0  2.444444   \n",
       "\n",
       "       AI Relevance   Other (negative)          Other (positive)  \\\n",
       "39653      4.833333                     warfare                    \n",
       "\n",
       "       Article Year                                Processed_Paragraph  \\\n",
       "39653             0  [warfare, increasingly, guided, software, toda...   \n",
       "\n",
       "            Sentiment_Type  Sentiment_Value  \n",
       "39653  Military (negative)               14  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The article with a sentiment 'Value' of 14 is heavily associated with 'Military (negative)'\n",
    "data_melt_nonzero[data_melt_nonzero['Sentiment_Value'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create word count dataframe with 'Article ID', 'Article Date', 'Word', 'Count', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', 'Sentiment (Positive/Negative)', 'Value'\n",
    "# word_count_df = pd.DataFrame(columns=['Article ID', 'Article Date', 'Word', 'Count', 'NYT Section', 'Title', 'AI Mood', 'AI Relevance', 'Sentiment (Positive/Negative)', 'Value'])\n",
    "\n",
    "\n",
    "# expand 'Processed_Paragraph' column list entries into a row for each word\n",
    "data_word_expand = data_melt_nonzero.explode('Processed_Paragraph')\n",
    "# reset index\n",
    "data_word_expand.reset_index(drop=True, inplace=True)\n",
    "# rename 'Processed_Paragraph' column to 'Word'\n",
    "data_word_expand.rename(columns={'Processed_Paragraph': 'Word'}, inplace=True)\n",
    "# drop rows with NaN values\n",
    "# data_word_expand.dropna(inplace=True)\n",
    "# add count value from positive_word_counts and negative_word_counts to data_word_expand dataframe for each word and sentiment type\n",
    "data_word_expand['Count'] = data_word_expand.apply(lambda row: positive_word_counts[row['Word']] if row['Sentiment_Type'] in positive_columns else negative_word_counts[row['Word']], axis=1)\n",
    "# reset index\n",
    "data_word_expand.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493350, 15)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_word_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Article ID', 'Article Date', 'NYT section', 'Paragraph', 'Title', 'Fiction', 'AI Mood', 'AI Relevance', 'Other (negative)', 'Other (positive)', 'Article Year', 'Word', 'Sentiment_Type', 'Sentiment_Value', 'Count',\n"
     ]
    }
   ],
   "source": [
    "# print columns of data_word_expand in single line with '' around col name\n",
    "print(' '.join([f\"'{col}',\" for col in data_word_expand.columns.tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Sentiment_Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>must</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>keyed</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>single</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>individuals</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID   AI Mood  AI Relevance         Word  \\\n",
       "0  4fd156a18eb7c8105d63aed2  4.333333           5.0        robot   \n",
       "1  4fd156a18eb7c8105d63aed2  4.333333           5.0         must   \n",
       "2  4fd156a18eb7c8105d63aed2  4.333333           5.0        keyed   \n",
       "3  4fd156a18eb7c8105d63aed2  4.333333           5.0       single   \n",
       "4  4fd156a18eb7c8105d63aed2  4.333333           5.0  individuals   \n",
       "\n",
       "      Sentiment_Type  Sentiment_Value  Count  \n",
       "0  Cyborg (positive)                2   2084  \n",
       "1  Cyborg (positive)                2     65  \n",
       "2  Cyborg (positive)                2      1  \n",
       "3  Cyborg (positive)                2     25  \n",
       "4  Cyborg (positive)                2      9  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns in data_word_expand - only keep 'Article ID', 'Word' 'Sentiment_Type', 'AI Mood', 'Sentiment_Value', 'AI Relevance', 'Count'\n",
    "data_word_expand_opt = data_word_expand.drop(['Article Date', 'Article Year', 'NYT section', 'Paragraph', 'Title', 'Fiction', 'Other (negative)', 'Other (positive)'], axis=1)\n",
    "\n",
    "data_word_expand_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_word_expand[data_word_expand['Word'] == 'robot'].sort_values(by='Article ID', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word_expand_opt.to_csv('data/data_concat_word_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Formatted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to 'data/ai_concat_pivot.csv'\n",
    "# data_melt_nonzero_op = data_melt_nonzero.drop(['Processed_Paragraph'], axis=1)\n",
    "output_path = 'data/ai_concat_pivot.csv'\n",
    "data_melt_nonzero_op.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word count dataset from 'Processed_Paragraph'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Article Year</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>4fd156a18eb7c8105d63aed2</td>\n",
       "      <td>1986-08-10 00:00:00+00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The robot must be keyed to a single individual...</td>\n",
       "      <td>TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>could be the tool that a handicapped person ...</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>['robot', 'must', 'keyed', 'single', 'individu...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>4fd16d848eb7c8105d660007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The F.B.I. is enthusiastic about Big Floyd, wh...</td>\n",
       "      <td>'BIG FLOYD' JOINS THE FORCE</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td></td>\n",
       "      <td>Criminal Investigation Lesser Crimes     diffe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['fbi', 'enthusiastic', 'big', 'floyd', 'whose...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>4fd1707b8eb7c8105d66317b</td>\n",
       "      <td>1986-08-10 00:00:00+00:00</td>\n",
       "      <td>Arts</td>\n",
       "      <td>''Condor,'' on the other hand, tries to be amu...</td>\n",
       "      <td>WHEN THE SLUSH PILE COMES TO LIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1986.0</td>\n",
       "      <td>['condor', 'hand', 'tries', 'amusing', 'after'...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>4fd1781e8eb7c8105d66ef93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>''The Tomorrow Makers,'' by Grant Fjermedal ($...</td>\n",
       "      <td>HOW TO AVOID TUNNEL VISION</td>\n",
       "      <td>0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>AI minds are wildly different from hum...</td>\n",
       "      <td>robotic immortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tomorrow', 'makers', 'grant', 'fjermedal', '...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275</td>\n",
       "      <td>4fd190318eb7c8105d696da7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology; Science; Week in Review</td>\n",
       "      <td>WHEN the computer scientist John McCarthy coin...</td>\n",
       "      <td>IDEAS AND TRENDS: Can Machines Learn to Think?...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>AI companies failing</td>\n",
       "      <td>science and technology development suppo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['computer', 'scientist', 'john', 'mccarthy', ...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                Article ID               Article Date  \\\n",
       "0          16  4fd156a18eb7c8105d63aed2  1986-08-10 00:00:00+00:00   \n",
       "1         115  4fd16d848eb7c8105d660007                        NaN   \n",
       "2         125  4fd1707b8eb7c8105d66317b  1986-08-10 00:00:00+00:00   \n",
       "3         162  4fd1781e8eb7c8105d66ef93                        NaN   \n",
       "4         275  4fd190318eb7c8105d696da7                        NaN   \n",
       "\n",
       "                           NYT section  \\\n",
       "0                                 U.S.   \n",
       "1                                 U.S.   \n",
       "2                                 Arts   \n",
       "3                             Business   \n",
       "4  Technology; Science; Week in Review   \n",
       "\n",
       "                                           Paragraph  \\\n",
       "0  The robot must be keyed to a single individual...   \n",
       "1  The F.B.I. is enthusiastic about Big Floyd, wh...   \n",
       "2  ''Condor,'' on the other hand, tries to be amu...   \n",
       "3  ''The Tomorrow Makers,'' by Grant Fjermedal ($...   \n",
       "4  WHEN the computer scientist John McCarthy coin...   \n",
       "\n",
       "                                               Title  Fiction   AI Mood  \\\n",
       "0       TO ASSIST HANDICAPPED, A ROBOT THAT CAN HEAR        0  4.333333   \n",
       "1                        'BIG FLOYD' JOINS THE FORCE        0  3.666667   \n",
       "2                  WHEN THE SLUSH PILE COMES TO LIFE        1  3.000000   \n",
       "3                         HOW TO AVOID TUNNEL VISION        0  3.111111   \n",
       "4  IDEAS AND TRENDS: Can Machines Learn to Think?...        0  2.888889   \n",
       "\n",
       "   AI Relevance                                   Other (negative)  \\\n",
       "0      5.000000                                                      \n",
       "1      5.000000                                                      \n",
       "2      3.333333                                                      \n",
       "3      4.666667          AI minds are wildly different from hum...   \n",
       "4      4.555556                           AI companies failing       \n",
       "\n",
       "                                    Other (positive)  Article Year  \\\n",
       "0    could be the tool that a handicapped person ...        1986.0   \n",
       "1  Criminal Investigation Lesser Crimes     diffe...           NaN   \n",
       "2                                                           1986.0   \n",
       "3                           robotic immortality                NaN   \n",
       "4        science and technology development suppo...           NaN   \n",
       "\n",
       "                                 Processed_Paragraph     Sentiment_Type  Value  \n",
       "0  ['robot', 'must', 'keyed', 'single', 'individu...  Cyborg (positive)      2  \n",
       "1  ['fbi', 'enthusiastic', 'big', 'floyd', 'whose...  Cyborg (positive)      1  \n",
       "2  ['condor', 'hand', 'tries', 'amusing', 'after'...  Cyborg (positive)      1  \n",
       "3  ['tomorrow', 'makers', 'grant', 'fjermedal', '...  Cyborg (positive)      2  \n",
       "4  ['computer', 'scientist', 'john', 'mccarthy', ...  Cyborg (positive)      1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat = pd.read_csv(output_path)\n",
    "data_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
