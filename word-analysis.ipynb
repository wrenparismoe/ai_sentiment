{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>Paragraph number</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>...</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Cyborg (positive)</th>\n",
       "      <th>Decisions (positive)</th>\n",
       "      <th>Education (positive)</th>\n",
       "      <th>Entertain (positive)</th>\n",
       "      <th>Healthcare (positive)</th>\n",
       "      <th>Singularity (positive)</th>\n",
       "      <th>Transportation (positive)</th>\n",
       "      <th>Work (positive)</th>\n",
       "      <th>Other (positive)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fd1cbc98eb7c8105d701286</td>\n",
       "      <td>1996-10-06 00:00:00 UTC</td>\n",
       "      <td>18</td>\n",
       "      <td>New York and Region</td>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>LONG ISLAND JOURNAL</td>\n",
       "      <td>1472</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fd1cbc98eb7c8105d701286</td>\n",
       "      <td>1996-10-06 00:00:00 UTC</td>\n",
       "      <td>18</td>\n",
       "      <td>New York and Region</td>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>LONG ISLAND JOURNAL</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fd1cbc98eb7c8105d701286</td>\n",
       "      <td>1996-10-06 00:00:00 UTC</td>\n",
       "      <td>18</td>\n",
       "      <td>New York and Region</td>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>LONG ISLAND JOURNAL</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54b0793b7988100e21965770</td>\n",
       "      <td>2006-07-31 00:00:00 UTC</td>\n",
       "      <td>16</td>\n",
       "      <td>Technology</td>\n",
       "      <td>That phrase was coined in the 1970۪s by Masahi...</td>\n",
       "      <td>Camera System Creates Sophisticated 3-D Effects</td>\n",
       "      <td>3053</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54b0793b7988100e21965770</td>\n",
       "      <td>2006-07-31 00:00:00 UTC</td>\n",
       "      <td>16</td>\n",
       "      <td>Technology</td>\n",
       "      <td>That phrase was coined in the 1970۪s by Masahi...</td>\n",
       "      <td>Camera System Creates Sophisticated 3-D Effects</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article ID             Article Date Paragraph number  \\\n",
       "0  4fd1cbc98eb7c8105d701286  1996-10-06 00:00:00 UTC               18   \n",
       "1  4fd1cbc98eb7c8105d701286  1996-10-06 00:00:00 UTC               18   \n",
       "2  4fd1cbc98eb7c8105d701286  1996-10-06 00:00:00 UTC               18   \n",
       "3  54b0793b7988100e21965770  2006-07-31 00:00:00 UTC               16   \n",
       "4  54b0793b7988100e21965770  2006-07-31 00:00:00 UTC               16   \n",
       "\n",
       "           NYT section                                          Paragraph  \\\n",
       "0  New York and Region  Thus, next weekend will feature the robot who ...   \n",
       "1  New York and Region  Thus, next weekend will feature the robot who ...   \n",
       "2  New York and Region  Thus, next weekend will feature the robot who ...   \n",
       "3           Technology  That phrase was coined in the 1970۪s by Masahi...   \n",
       "4           Technology  That phrase was coined in the 1970۪s by Masahi...   \n",
       "\n",
       "                                             Title  WorkTimeInSeconds  \\\n",
       "0                              LONG ISLAND JOURNAL               1472   \n",
       "1                              LONG ISLAND JOURNAL                 49   \n",
       "2                              LONG ISLAND JOURNAL                 66   \n",
       "3  Camera System Creates Sophisticated 3-D Effects               3053   \n",
       "4  Camera System Creates Sophisticated 3-D Effects                 25   \n",
       "\n",
       "   AI Mood  AI Relevance  Fiction  ...  Other (negative)  Cyborg (positive)  \\\n",
       "0        4             5        0  ...                {}                  0   \n",
       "1        4             5        0  ...                {}                  0   \n",
       "2        5             5        0  ...                {}                  0   \n",
       "3        3             4        0  ...                {}                  0   \n",
       "4        3             4        0  ...                {}                  0   \n",
       "\n",
       "   Decisions (positive)  Education (positive)  Entertain (positive)  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   Healthcare (positive)  Singularity (positive) Transportation (positive)  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   Work (positive)  Other (positive)  \n",
       "0                0                {}  \n",
       "1                0                {}  \n",
       "2                0                {}  \n",
       "3                0                {}  \n",
       "4                0                {}  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"data/ai-perception.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "This step will include tokenizing the paragraphs, removing stop words, and applying stemming to the words. We will then categorize the words into positive and negative associations based on the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/wpm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/wpm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing nltk resources for text preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial stop words: 36\n"
     ]
    }
   ],
   "source": [
    "# Define common English stop words - set class data type\n",
    "stop_words = {'thus', 'the', 'and', 'to', 'of', 'a', 'in', 'that', 'is', 'was', 'he', 'for', 'it', 'with', 'as', 'his', 'on', 'be', 'at', 'by', 'i', 'this', 'had', 'not', 'but', 'from', 'or', 'have', 'an', 'they', 'which', 'you', 'were', 'her', 'their', 'we'}\n",
    "print(\"Initial stop words:\", len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: 722\n"
     ]
    }
   ],
   "source": [
    "# load frequent words dataset - columns are 'word' and 'count'\n",
    "freq_words = pd.read_csv('data/unigram_freq.csv')\n",
    "\n",
    "# add 1 and 2 letter words to the stop_words set if they are not already there\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if len(word) <= 2:\n",
    "        stop_words.add(word)\n",
    "\n",
    "print(\"Stop words:\", len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: 767\n"
     ]
    }
   ],
   "source": [
    "# add stop words with count more than 550000000\n",
    "for i in range(len(freq_words['word'])):\n",
    "    word = str(freq_words['word'][i])\n",
    "    if freq_words['count'][i] > 550000000:\n",
    "        stop_words.add(word)\n",
    "\n",
    "print(\"Stop words:\", len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: 100767\n"
     ]
    }
   ],
   "source": [
    "# create pandas series with words with count less than 100,000\n",
    "less_freq_words = freq_words[freq_words['count'] < 100000]['word'].tail(100000).tolist()\n",
    "# add less_freq_words to stop_words set\n",
    "stop_words = stop_words.union(set(less_freq_words))\n",
    "print(\"Stop words:\", len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to tokenize text (split by spaces and remove punctuation)\n",
    "def custom_tokenize(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize by spaces\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Function to preprocess text (tokenize and remove stop words)\n",
    "# def custom_preprocess_text(text):\n",
    "#     # Tokenize the text\n",
    "#     tokens = custom_tokenize(text)\n",
    "#     # Remove stop words\n",
    "#     tokens = [word for word in tokens if word not in stop_words]\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to preprocess text (tokenize and remove stop words) with handling for missing or non-string values\n",
    "def custom_preprocess_text(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = custom_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>[next, weekend, feature, robot, named, sico, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>[next, weekend, feature, robot, named, sico, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thus, next weekend will feature the robot who ...</td>\n",
       "      <td>[next, weekend, feature, robot, named, sico, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That phrase was coined in the 1970۪s by Masahi...</td>\n",
       "      <td>[phrase, coined, 1970۪s, masahiro, mori, japan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That phrase was coined in the 1970۪s by Masahi...</td>\n",
       "      <td>[phrase, coined, 1970۪s, masahiro, mori, japan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Paragraph  \\\n",
       "0  Thus, next weekend will feature the robot who ...   \n",
       "1  Thus, next weekend will feature the robot who ...   \n",
       "2  Thus, next weekend will feature the robot who ...   \n",
       "3  That phrase was coined in the 1970۪s by Masahi...   \n",
       "4  That phrase was coined in the 1970۪s by Masahi...   \n",
       "\n",
       "                                 Processed_Paragraph  \n",
       "0  [next, weekend, feature, robot, named, sico, p...  \n",
       "1  [next, weekend, feature, robot, named, sico, p...  \n",
       "2  [next, weekend, feature, robot, named, sico, p...  \n",
       "3  [phrase, coined, 1970۪s, masahiro, mori, japan...  \n",
       "4  [phrase, coined, 1970۪s, masahiro, mori, japan...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'Article Date' column to datetime, coercing errors\n",
    "data['Article Date'] = pd.to_datetime(data['Article Date'], errors='coerce')\n",
    "\n",
    "# Apply the custom preprocessing function to the 'Paragraph' column\n",
    "data['Processed_Paragraph'] = data['Paragraph'].apply(custom_preprocess_text)\n",
    "\n",
    "# Show the processed paragraphs in the first few rows\n",
    "data[['Paragraph', 'Processed_Paragraph']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Word Associations (Positive and Negative)\n",
    "\n",
    "To find words with the most positive and negative associations, we analyze the processed paragraphs in conjunction with the positive and negative columns in the dataset. We create functions to aggregate the word counts based on these associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count words with positive and negative associations\n",
    "def count_associations(row):\n",
    "    # Extract processed paragraph\n",
    "    words = row['Processed_Paragraph']\n",
    "    # Initialize counters for positive and negative associations\n",
    "    positive_counter = Counter()\n",
    "    negative_counter = Counter()\n",
    "    # Iterate through words and update counters based on associations in the row\n",
    "    for word in words:\n",
    "        if any(row[col] > 0 for col in positive_columns):\n",
    "            positive_counter[word] += 1\n",
    "        if any(row[col] > 0 for col in negative_columns):\n",
    "            negative_counter[word] += 1\n",
    "    return positive_counter, negative_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns representing positive and negative associations\n",
    "positive_columns = ['Cyborg (positive)', 'Decisions (positive)', 'Education (positive)', 'Entertain (positive)', 'Healthcare (positive)', 'Singularity (positive)', 'Transportation (positive)', 'Work (positive)']\n",
    "negative_columns = ['Controling AI (negative)', 'Cyborg (negative)', 'Ethics (negative)', 'Military (negative)', 'Progress (negative)', 'Singularity (negative)', 'Work (negative)']\n",
    "\n",
    "# Define remaining columns\n",
    "all_columns = data.columns.tolist()\n",
    "remaining_columns = [col for col in all_columns if col not in positive_columns and col not in negative_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to count word associations\n",
    "positive_word_counts = Counter()\n",
    "negative_word_counts = Counter()\n",
    "for _, row in data.iterrows():\n",
    "    positive, negative = count_associations(row)\n",
    "    positive_word_counts += positive\n",
    "    negative_word_counts += negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive word count: 17720\n",
      "negative word count: 10571\n",
      "robot in positive words: True \n",
      "robot in negative words: True\n"
     ]
    }
   ],
   "source": [
    "# print length of positive_word_counts and negative_word_counts dictionaries\n",
    "print('positive word count:', len(positive_word_counts))\n",
    "print('negative word count:', len(negative_word_counts))\n",
    "# check if 'robot' is contained in negative_word_counts\n",
    "print('robot in positive words:', 'robot' in positive_word_counts, '\\nrobot in negative words:', 'robot' in negative_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot (positive): 2169\n",
      "robot (negative): 465\n"
     ]
    }
   ],
   "source": [
    "print('robot (positive):', positive_word_counts['robot'])\n",
    "print('robot (negative):', negative_word_counts['robot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: [('robot', 2169), ('intelligence', 1915), ('artificial', 1876), ('its', 953), ('like', 781), ('said', 756), ('computer', 656), ('human', 603), ('could', 556), ('robots', 540)] \n",
      "negative: [('intelligence', 1110), ('artificial', 1047), ('human', 470), ('robot', 465), ('computer', 348), ('—', 345), ('its', 318), ('said', 284), ('like', 272), ('robots', 241)]\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 positive and negative words\n",
    "top_positive_words = positive_word_counts.most_common(10)\n",
    "top_negative_words = negative_word_counts.most_common(10)\n",
    "\n",
    "# top_positive_words, top_negative_words\n",
    "print('positive:', top_positive_words, '\\nnegative:', top_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We want to output the positive and negative words in a new dataset in CSV form with the below structure. There should be an entry for each of the instances of a word in a paragraph from the original articles.\n",
    "Article ID\tWord\tTotal Frequency\tSentiment (Positive/Negative)\n",
    "1234\tRobot\t200\tPositive\n",
    "2345\tRobot\t345\tNegative\n",
    "3456\tRobot\t345\tNegative\n",
    "\"\"\"\n",
    "# Create a new dataframe to hold the results\n",
    "results = pd.DataFrame(columns=['Article ID', 'Word', 'Total Frequency', 'Sentiment (Positive/Negative)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Article Date</th>\n",
       "      <th>Paragraph number</th>\n",
       "      <th>NYT section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Title</th>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <th>AI Mood</th>\n",
       "      <th>AI Relevance</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Other (negative)</th>\n",
       "      <th>Other (positive)</th>\n",
       "      <th>Processed_Paragraph</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4fd2a5648eb7c8105d88ca51</td>\n",
       "      <td>2004-11-28 00:00:00+00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>Technology; Science; Magazine</td>\n",
       "      <td>Some of those functions, especially involving ...</td>\n",
       "      <td>A Robot For the Masses</td>\n",
       "      <td>618</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[some, those, functions, especially, involving...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4fd1a8b88eb7c8105d6c4d24</td>\n",
       "      <td>1991-11-03 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Movies; Arts</td>\n",
       "      <td>Is it progress when a Terminator wants to weep...</td>\n",
       "      <td>Screen Robots Tell a Tale of Mankind</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[progress, terminator, wants, weep, terminator...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4fd1b1f58eb7c8105d6d47db</td>\n",
       "      <td>1992-04-25 00:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Technology; Business</td>\n",
       "      <td>The new robot gripper solves the problem with ...</td>\n",
       "      <td>Patents; A Simple Method for Robot's Grip</td>\n",
       "      <td>665</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[robot, gripper, solves, problem, simple, slid...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>4fd3a2858eb7c8105d8ea970</td>\n",
       "      <td>2011-12-25 17:30:32+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>This is why, in my view, we need to think long...</td>\n",
       "      <td>The Future of Moral Machines</td>\n",
       "      <td>643</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[why, need, think, long, hard, machine, morali...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4fd3958e8eb7c8105d8cb8ae</td>\n",
       "      <td>2009-06-17 11:00:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Health</td>\n",
       "      <td>The genesis of much of the ab work we do these...</td>\n",
       "      <td>Is Your Ab Workout Hurting Your Back?</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[genesis, much, work, these, days, probably, l...</td>\n",
       "      <td>Cyborg (positive)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Article ID              Article Date Paragraph number  \\\n",
       "27   4fd2a5648eb7c8105d88ca51 2004-11-28 00:00:00+00:00               29   \n",
       "76   4fd1a8b88eb7c8105d6c4d24 1991-11-03 00:00:00+00:00                0   \n",
       "117  4fd1b1f58eb7c8105d6d47db 1992-04-25 00:00:00+00:00                5   \n",
       "183  4fd3a2858eb7c8105d8ea970 2011-12-25 17:30:32+00:00                4   \n",
       "188  4fd3958e8eb7c8105d8cb8ae 2009-06-17 11:00:42+00:00                0   \n",
       "\n",
       "                       NYT section  \\\n",
       "27   Technology; Science; Magazine   \n",
       "76                    Movies; Arts   \n",
       "117           Technology; Business   \n",
       "183                        Opinion   \n",
       "188                         Health   \n",
       "\n",
       "                                             Paragraph  \\\n",
       "27   Some of those functions, especially involving ...   \n",
       "76   Is it progress when a Terminator wants to weep...   \n",
       "117  The new robot gripper solves the problem with ...   \n",
       "183  This is why, in my view, we need to think long...   \n",
       "188  The genesis of much of the ab work we do these...   \n",
       "\n",
       "                                         Title  WorkTimeInSeconds  AI Mood  \\\n",
       "27                      A Robot For the Masses                618        5   \n",
       "76        Screen Robots Tell a Tale of Mankind                 39        3   \n",
       "117  Patents; A Simple Method for Robot's Grip                665        5   \n",
       "183               The Future of Moral Machines                643        5   \n",
       "188      Is Your Ab Workout Hurting Your Back?                 80        5   \n",
       "\n",
       "     AI Relevance  Fiction Other (negative) Other (positive)  \\\n",
       "27              5        0               {}               {}   \n",
       "76              4        1               {}               {}   \n",
       "117             5        0               {}               {}   \n",
       "183             3        0               {}               {}   \n",
       "188             5        1               {}               {}   \n",
       "\n",
       "                                   Processed_Paragraph          Sentiment  \\\n",
       "27   [some, those, functions, especially, involving...  Cyborg (positive)   \n",
       "76   [progress, terminator, wants, weep, terminator...  Cyborg (positive)   \n",
       "117  [robot, gripper, solves, problem, simple, slid...  Cyborg (positive)   \n",
       "183  [why, need, think, long, hard, machine, morali...  Cyborg (positive)   \n",
       "188  [genesis, much, work, these, days, probably, l...  Cyborg (positive)   \n",
       "\n",
       "     Value  \n",
       "27       1  \n",
       "76       1  \n",
       "117      1  \n",
       "183      1  \n",
       "188      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the sentiment columns into rows creating a new row for each sentiment that has a 1 entry\n",
    "data_long = pd.melt(data, id_vars=remaining_columns, value_vars=positive_columns + negative_columns, var_name='Sentiment', value_name='Value')\n",
    "# drop rows where the sentiment is 0\n",
    "data_long = data_long[data_long['Value'] != 0]\n",
    "data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_data = pd.melt(data, id_vars=remaining_columns, value_vars=positive_columns + negative_columns, var_name='Sentiment', value_name='Value')\n",
    "# Drop rows where the value is 0\n",
    "melted_data = melted_data[melted_data['Value'] > 0]\n",
    "# Drop the value column\n",
    "melted_data.drop(columns=['Value'], inplace=True)\n",
    "# Sort by article ID and sentiment\n",
    "melted_data.sort_values(by=['Article ID', 'Sentiment'], inplace=True)\n",
    "# Reset the index\n",
    "melted_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash import dcc, html, Input, Output\n",
    "import dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for positive words\n",
    "positive_df = pd.DataFrame(top_positive_words, columns=['Word', 'Count'])\n",
    "# Create DataFrame for negative words\n",
    "negative_df = pd.DataFrame(top_negative_words, columns=['Word', 'Count'])\n",
    "\n",
    "# Generate word clouds\n",
    "positive_word_cloud = px.treemap(positive_df, path=['Word'], values='Count', title=\"Top Positive Words\")\n",
    "negative_word_cloud = px.treemap(negative_df, path=['Word'], values='Count', title=\"Top Negative Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar charts\n",
    "positive_bar_chart = go.Figure(data=[go.Bar(x=positive_df['Word'], y=positive_df['Count'])])\n",
    "negative_bar_chart = go.Figure(data=[go.Bar(x=negative_df['Word'], y=negative_df['Count'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the 'Health' section\n",
    "health_data = data[data['NYT section'] == 'Health']\n",
    "# Count words for the 'Health' section\n",
    "health_word_counts = Counter()\n",
    "for words in health_data['Processed_Paragraph']:\n",
    "    health_word_counts += Counter(words)\n",
    "# Create a bar chart\n",
    "health_words_df = pd.DataFrame(health_word_counts.most_common(10), columns=['Word', 'Count'])\n",
    "health_bar_chart = go.Figure(data=[go.Bar(x=health_words_df['Word'], y=health_words_df['Count'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Initialize the Dash app\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m app \u001b[39m=\u001b[39m dash\u001b[39m.\u001b[39mDash(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Dropdown for word selection\u001b[39;00m\n\u001b[1;32m      5\u001b[0m word_dropdown \u001b[39m=\u001b[39m dcc\u001b[39m.\u001b[39mDropdown(\n\u001b[1;32m      6\u001b[0m     \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mword-dropdown\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     options\u001b[39m=\u001b[39m[{\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: word, \u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m: word} \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m positive_word_counts\u001b[39m.\u001b[39mkeys()],\n\u001b[1;32m      8\u001b[0m     value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrobot\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Default value\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dash' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Dropdown for word selection\n",
    "word_dropdown = dcc.Dropdown(\n",
    "    id='word-dropdown',\n",
    "    options=[{'label': word, 'value': word} for word in positive_word_counts.keys()],\n",
    "    value='robot'  # Default value\n",
    ")\n",
    "\n",
    "# Function to update word trend chart\n",
    "@app.callback(\n",
    "    Output('word-trend-chart', 'figure'),\n",
    "    Input('word-dropdown', 'value')\n",
    ")\n",
    "def update_word_trend(selected_word):\n",
    "    # Convert the 'Article Date' column to datetime, coercing errors\n",
    "    # data['Article_Date_DT'] = pd.to_datetime(data['Article Date'], errors='coerce')\n",
    "    \n",
    "    # Filter data by the selected word\n",
    "    word_trend_data = data[data['Processed_Paragraph'].apply(lambda x: selected_word in x)]\n",
    "\n",
    "    # Extract years and count occurrences\n",
    "    word_trend_data['Year'] = pd.to_datetime(word_trend_data['Article Date']).dt.year\n",
    "    word_counts_by_year = word_trend_data.groupby('Year').size().reset_index(name='Count')\n",
    "\n",
    "    # Create a line chart\n",
    "    figure = px.line(word_counts_by_year, x='Year', y='Count', title=f\"Trend of the Word '{selected_word}' over Time\")\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the dahsboard execution at the end [for debugging purposes]\n",
    "\n",
    "# app.layout = html.Div([\n",
    "#     html.H1(\"AI Perception Analysis Dashboard\"),\n",
    "#     dcc.Graph(figure=positive_word_cloud),\n",
    "#     dcc.Graph(figure=negative_word_cloud),\n",
    "#     dcc.Graph(figure=positive_bar_chart),\n",
    "#     dcc.Graph(figure=negative_bar_chart),\n",
    "#     dcc.Graph(figure=health_bar_chart),\n",
    "#     html.Div([\n",
    "#         html.H3(\"Select a Word for Trend Analysis:\"),\n",
    "#         word_dropdown,\n",
    "#         dcc.Graph(id='word-trend-chart'),\n",
    "#         # Add other components as needed\n",
    "#     ])\n",
    "# ])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Positive or Negative Connotations of a Selected Word\n",
    "\n",
    "We create two bar charts to represent the positive and negative associations of a selected word over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to update positive and negative connotations charts\n",
    "# @app.callback(\n",
    "#     [Output('positive-connotation-chart', 'figure'),\n",
    "#      Output('negative-connotation-chart', 'figure')],\n",
    "#     Input('word-dropdown', 'value')\n",
    "# )\n",
    "# def update_connotation_charts(selected_word):\n",
    "#     # Filter data by the selected word\n",
    "#     connotation_data = data[data['Processed_Paragraph'].apply(lambda x: selected_word in x)]\n",
    "\n",
    "#     # Extract years\n",
    "#     connotation_data['Year'] = pd.to_datetime(connotation_data['Article Date']).dt.year\n",
    "\n",
    "#     # Calculate positive and negative scores by year\n",
    "#     positive_scores_by_year = connotation_data.groupby('Year')[positive_columns].sum().sum(axis=1).reset_index(name='Positive Score')\n",
    "#     negative_scores_by_year = connotation_data.groupby('Year')[negative_columns].sum().sum(axis=1).reset_index(name='Negative Score')\n",
    "\n",
    "#     # Create bar charts\n",
    "#     positive_figure = px.bar(positive_scores_by_year, x='Year', y='Positive Score', title=f\"Positive Connotations of the Word '{selected_word}' over Time\")\n",
    "#     negative_figure = px.bar(negative_scores_by_year, x='Year', y='Negative Score', title=f\"Negative Connotations of the Word '{selected_word}' over Time\")\n",
    "    \n",
    "#     return positive_figure, negative_figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.layout = html.Div([\n",
    "#     # ... existing components\n",
    "#     html.Div([\n",
    "#         html.H3(\"Select a Word for Trend and Connotation Analysis:\"),\n",
    "#         word_dropdown,\n",
    "#         dcc.Graph(id='word-trend-chart'),\n",
    "#         dcc.Graph(id='positive-connotation-chart'),\n",
    "#         dcc.Graph(id='negative-connotation-chart'),\n",
    "#         # Add other components as needed\n",
    "#     ])\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to update word frequency chart for a specific year\n",
    "# @app.callback(\n",
    "#     Output('word-frequency-chart', 'figure'),\n",
    "#     [Input('word-dropdown', 'value'),\n",
    "#      Input('year-input', 'value')]  # Assuming a numeric input component for the year\n",
    "# )\n",
    "# def update_word_frequency_chart(selected_word, selected_year):\n",
    "#     # Filter data by the selected word and year\n",
    "#     frequency_data = data[data['Processed_Paragraph'].apply(lambda x: selected_word in x)]\n",
    "#     frequency_data['Year'] = pd.to_datetime(frequency_data['Article Date']).dt.year\n",
    "#     frequency_data = frequency_data[frequency_data['Year'] == selected_year]\n",
    "\n",
    "#     # Count occurrences\n",
    "#     word_count = len(frequency_data)\n",
    "\n",
    "#     # Create a bar chart\n",
    "#     figure = go.Figure(data=[go.Bar(x=[selected_word], y=[word_count])])\n",
    "#     figure.update_layout(title=f\"Frequency of the Word '{selected_word}' in {selected_year}\")\n",
    "    \n",
    "#     return figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Positive or Negative Connotations of a Selected Word\n",
    "\n",
    "We'll create a pie chart that shows whether the selected word is used mostly in positive or negative connotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update pie chart based on selected word's positive/negative association\n",
    "@app.callback(\n",
    "    Output('word-association-pie', 'figure'),\n",
    "    Input('word-dropdown', 'value')\n",
    ")\n",
    "def update_word_association(selected_word):\n",
    "    positive_count = positive_word_counts[selected_word]\n",
    "    negative_count = negative_word_counts[selected_word]\n",
    "    association_df = pd.DataFrame({'Association': ['Positive', 'Negative'], 'Count': [positive_count, negative_count]})\n",
    "    figure = px.pie(association_df, names='Association', values='Count', title=f\"Positive/Negative Associations of '{selected_word}'\")\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly Frequency Analysis for a Specific Year (e.g., 2016)\n",
    "\n",
    "We'll create a bar chart that shows the frequency of the selected word in a specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update bar chart for the frequency of the selected word in 2016\n",
    "@app.callback(\n",
    "    Output('word-frequency-year', 'figure'),\n",
    "    Input('word-dropdown', 'value')\n",
    ")\n",
    "def update_word_frequency(selected_word):\n",
    "    word_data_2016 = data[(data['Processed_Paragraph'].apply(lambda x: selected_word in x)) & (pd.to_datetime(data['Article Date']).dt.year == 2016)]\n",
    "    word_count_2016 = len(word_data_2016)\n",
    "    frequency_df = pd.DataFrame({'Word': [selected_word], 'Frequency': [word_count_2016]})\n",
    "    figure = px.bar(frequency_df, x='Word', y='Frequency', title=f\"Frequency of '{selected_word}' in 2016\")\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Details for the Dashboard Layout\n",
    "\n",
    "We'll integrate all the visualizations and interactive components to create the final dashboard layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff71312e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_110065/2117205579.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app.layout = html.Div([\n",
    "    html.H1(\"AI Perception Analysis Dashboard\"),\n",
    "    dcc.Graph(figure=positive_word_cloud),\n",
    "    dcc.Graph(figure=negative_word_cloud),\n",
    "    dcc.Graph(figure=positive_bar_chart),\n",
    "    dcc.Graph(figure=negative_bar_chart),\n",
    "    dcc.Graph(figure=health_bar_chart),\n",
    "    html.Div([\n",
    "        html.H3(\"Select a Word for Analysis:\"),\n",
    "        word_dropdown,\n",
    "        dcc.Graph(id='word-trend-chart'),\n",
    "        dcc.Graph(id='word-association-pie'),\n",
    "        dcc.Graph(id='word-frequency-year'),\n",
    "    ])\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
